{"meta":{"title":"thk_days","subtitle":"I think that that that that that article wrote on the blog was wrong.","description":"程序猿 | 熬夜猫 | 次元狗","author":"zxc","url":"http://qhzxc0015.com"},"pages":[{"title":"guestbook","date":"2017-08-06T18:22:45.000Z","updated":"2017-08-07T10:33:37.106Z","comments":true,"path":"guestbook/index.html","permalink":"http://qhzxc0015.com/guestbook/index.html","excerpt":"","text":""},{"title":"tags","date":"2017-07-21T12:44:19.000Z","updated":"2017-07-21T12:56:21.358Z","comments":true,"path":"tags/index.html","permalink":"http://qhzxc0015.com/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2017-08-06T21:44:46.000Z","updated":"2017-08-06T21:52:18.927Z","comments":true,"path":"categories/index.html","permalink":"http://qhzxc0015.com/categories/index.html","excerpt":"","text":""},{"title":"photos","date":"2017-08-07T01:36:11.000Z","updated":"2017-08-08T15:29:59.443Z","comments":true,"path":"photos/index.html","permalink":"http://qhzxc0015.com/photos/index.html","excerpt":"","text":"学校主页 学校主页 学校主页 学校主页 学校主页 学校主页 学校主页 学校主页 学校主页 学校主页 $(\"#Thplayer\").thplayer({ title: \"稻香\", author: \"周杰伦\", cover: \"http://p4.music.126.net/gYwk-n_UWAtOfDZBEV04dQ==/7699879929738059.jpg\", music: \"http://ou9i51fe5.bkt.clouddn.com/music/%E7%A8%BB%E9%A6%99.mp3\" });"},{"title":"project","date":"2017-08-07T02:21:43.000Z","updated":"2017-08-07T17:08:27.067Z","comments":true,"path":"project/index.html","permalink":"http://qhzxc0015.com/project/index.html","excerpt":"","text":""}],"posts":[{"title":"CoreOS","slug":"05. coreos搭建","date":"2017-08-17T08:32:31.000Z","updated":"2017-08-17T08:32:54.141Z","comments":true,"path":"2017/08/17/05. coreos搭建.html","link":"","permalink":"http://qhzxc0015.com/2017/08/17/05. coreos搭建.html","excerpt":"CoreOS是一个基于Linux 内核的轻量级操作系统，为了计算机集群的基础设施建设而生，专注于自动化，轻松部署，安全，可靠，规模化。作为一个操作系统，CoreOS 提供了在应用容器内部署应用所需要的基础功能环境以及一系列用于服务发现和配置共享的内建工具。","text":"CoreOS是一个基于Linux 内核的轻量级操作系统，为了计算机集群的基础设施建设而生，专注于自动化，轻松部署，安全，可靠，规模化。作为一个操作系统，CoreOS 提供了在应用容器内部署应用所需要的基础功能环境以及一系列用于服务发现和配置共享的内建工具。 参考文献： 使用Vagrant在Windows下部署开发环境 准备工作： 下载安装VirtualBox 下载安装Vagrant git获取Vagrantfile：git clone https://github.com/coreos/coreos-vagrant.git 下载完毕后进入coreos-vagrant文件夹，将config.rb.sample和user-data.sample的sample去掉，修改config.rb中 12$num_instances=1 $update_channel=&apos;alpha&apos; 操作： 启动：vagrant up 状态：vagrant status 进入：vagrant ssh core-01","categories":[],"tags":[{"name":"CoreOS docker","slug":"CoreOS-docker","permalink":"http://qhzxc0015.com/tags/CoreOS-docker/"}]},{"title":"Docker Registry","slug":"06. Registry搭建","date":"2017-08-17T08:22:58.000Z","updated":"2017-08-17T08:37:43.338Z","comments":true,"path":"2017/08/17/06. Registry搭建.html","link":"","permalink":"http://qhzxc0015.com/2017/08/17/06. Registry搭建.html","excerpt":"GFW真的强，所以国外镜像真的太难拉下来了,因此采用 docker registry 来存储镜像供其他节点使用","text":"GFW真的强，所以国外镜像真的太难拉下来了,因此采用 docker registry 来存储镜像供其他节点使用 1. Docker版国外镜像真的太难拉下来了,所以采用 docker registry 来存储镜像供其他节点使用,拉取registry镜像sudo docker pull hub.c.163.com/library/registry:2.6.0启动仓库sudo docker run -d -p 5000:5000 -v /docker/registry:/tmp/registry hub.c.163.com/library/registry:2.6.0将各个镜像上传到仓库12sudo docker tag gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64:1.14.2 202.193.74.222/k8s-dns-dnsmasq-nanny-amd64:1.14.2sudo docker push 202.193.74.222:5000/k8s-dns-dnsmasq-nanny-amd64:1.14.2 2. Harbor版参考文献：harbor搭建harbor搭建与问题修改 Harbor也是基于registry镜像进行搭建的,可视化界面比较友好,官网下载分为在线版和离线版,建议用离线版,因为在线版需要自己在国外网站拉取镜像,伟大的墙的威力还是有的,离线版就简单了,直接有版本对应好的镜像. 环境与配置安装环境:docker1.10+,python2.7+,docker-compose1.6.0+下载离线安装包harbor-offline,配置harbor.cfg修改: 123hostname = n2db_password = adminharbor_admin_password = admin #这个是登录密码 启动与访问通过docker-compose.yml修改端口号再通过./prepare来更新配置之后进行./install.sh来安装最后通过docker-compose up -d来启动启动后通过n2:80来访问仓库 登录与上传先进行登录docker login n2:80提示Login Succeeded为安装成功注:这里上传需要先在web端建好项目名,比如上传到仓库名library中: 12sudo docker tag n2:80/library/test:v1sudo docker push n2:80/library/test:v1 3. ErrorsE1: 1234test@Test1:~$ sudo docker push 202.193.74.222:5000/test:latest# ERRORThe push refers to a repository [202.193.74.222:5000/test]Get https://202.193.74.222:5000/v1/_ping: http: server gave HTTP response to HTTPS client 解决方法1:在/etc/docker/目录下，创建daemon.json文件。在文件中写入： 1&#123; &quot;insecure-registries&quot;:[&quot;ip:5000&quot;] &#125; 解决方法2:Centos中vim /etc/sysconfig/docker,在文件中添加: 12ADD_REGISTRY=&apos;--add-registry e2:80&apos;INSECURE_REGISTRY=&apos;--insecure-registry e2:80&apos; 解决方法3:Ubuntu中vim /etc/default/docker,在文件中添加: 1DOCKER_OPTS=&quot;--dns 8.8.8.8 --dns 8.8.4.4 --insecure-registry=n2:80&quot; 重启dockersudo systemctl restart dockerE2: 12345test@Test1:~$ sudo docker push n2:80/library/test:v185782553e37a: Waiting 745f5be9952c: Waiting denied: requested access to the resource is denied 解决方法1:先登录才可以上传,进行登录操作 解决方法2:用hosts名称会异常,建议直接使用ip E3: 1ERROR: for proxy Cannot start service proxy: driver failed programming external connectivity on endpoint nginx (fdeb3e538d5f8d714ea5c79a9f3f127f05f7ba5d519e09c4c30ef81f40b2fe77): Error starting userland proxy: listen tcp 0.0.0.0:80: bind: address already in use 端口占用问题,可以通过修改端口来完成,在harbor/docker-compose.yml中修改,比如此处的80端口修改为8080操作如下: 12345678910111213141516171819202122proxy: image: vmware/nginx:1.11.5-patched container_name: nginx restart: always volumes: - ./common/config/nginx:/etc/nginx:z networks: - harbor ports: - 8080:80 - 444:443 - 4443:4443 depends_on: - mysql - registry - ui - log logging: driver: &quot;syslog&quot; options: syslog-address: &quot;tcp://127.0.0.1:1514&quot; tag: &quot;proxy&quot; 注意这里修改了之后在上面问题E1,E2中的修改也端口 4. Shells批量上传脚本push_images.sh 1234567#!/bin/bashimages=(kube-proxy-amd64:v1.6.6 kube-scheduler-amd64:v1.6.6 kube-controller-manager-amd64:v1.6.6 kube-apiserver-amd64:v1.6.6 etcd-amd64:3.0.17 pause-amd64:3.0 kubernetes-dashboard-amd64:v1.6.1 k8s-dns-sidecar-amd64:1.14.2 k8s-dns-kube-dns-amd64:1.14.2 k8s-dns-dnsmasq-nanny-amd64:1.14.2 etcd:v3.1.5)for imageName in $&#123;images[@]&#125; ; do sudo docker tag gcr.io/google_containers/$imageName e2:5000/$imageName sudo docker push e2:5000/$imageName sudo docker rmi e2:5000/$imageNamedone 批量下载脚本pull_images.sh1234567#!/bin/bash## 标题 ##images=(kube-proxy-amd64:v1.6.6 kube-scheduler-amd64:v1.6.6 kube-controller-manager-amd64:v1.6.6 kube-apiserver-amd64:v1.6.6 etcd-amd64:3.0.17 pause-amd64:3.0 kubernetes-dashboard-amd64:v1.6.1 k8s-dns-sidecar-amd64:1.14.2 k8s-dns-kube-dns-amd64:1.14.2 k8s-dns-dnsmasq-nanny-amd64:1.14.2 etcd:v3.1.5)for imageName in $&#123;images[@]&#125; ; do sudo docker pull e2:5000/$imageName sudo docker tag e2:5000/$imageName gcr.io/google_containers/$imageName sudo docker rmi e2:5000/$imageNamedone","categories":[],"tags":[{"name":"Docker Harbor","slug":"Docker-Harbor","permalink":"http://qhzxc0015.com/tags/Docker-Harbor/"}]},{"title":"k8s设计方案","slug":"04. k8s设计方案","date":"2017-08-16T19:23:24.000Z","updated":"2017-08-17T07:34:15.590Z","comments":true,"path":"2017/08/17/04. k8s设计方案.html","link":"","permalink":"http://qhzxc0015.com/2017/08/17/04. k8s设计方案.html","excerpt":"Kubernetes作为Docker生态圈中重要一员,是Google多年大规模容器管理技术的开源版本，厉害厉害~不容小窥呀。","text":"Kubernetes作为Docker生态圈中重要一员,是Google多年大规模容器管理技术的开源版本，厉害厉害~不容小窥呀。 参考文献： 弹性伸缩与滚动升级 Kubernetes自动伸缩功能剖析 Kubernetes核心概念总结 闲谈Kubernetes 的主要特性和经验分享 Kubernetes：Google分布式容器技术初体验 相关概念1.1 Kubernetes核心概念 Kubernetes（k8s）是Google开源的自动化容器操作平台，为容器化的应用提供资源调度、部署运行、服务发现、扩容缩容等一整套功能，是一个全新的基于容器技术的分布式框架解决方案。 k8s有如下优秀特性： 自动化容器的部署和复制； 随时扩展或收缩容器规模； 将容器组织成组，并且提供容器间的负载均衡； 滚动升级应用程序容器的新版本； 提供容器弹性，一旦容器失效立刻用新容器替换。 使用Kubernetes只需一个部署文件，使用一条命令就可以部署多层容器（前端，后台等）的完整集群。 k8s的核心概念主要包括Pod、ReplicationController、Label。 PodPod是若干相关容器的组合，Pod包含的容器运行在同一台主机上，这些容器使用相同的网络命令空间、IP地址和端口，相互之间能通过localhost来发现和通信。另外，这些容器还可共享一块存储卷空间。在k8s中创建，调度和管理的最小单位就是Pod，而非容器，Pod通过提供更高层次的抽象，提供了更加灵活的部署和管理模式。 ReplicationController （RC）RC是用来管理Pod的，每个RC由一个或多个Pod组成；在RC被创建之后，系统将会保持RC中的可用Pod的个数与创建RC时定义的Pod个数一致，如果Pod个数小于定义的个数，RC会启动新的Pod，反之则会杀死多余的Pod。 LabelLabel是用于区分Pod、Service、RC的key/value键值对。Pod、Service、RC可以有多个label，但是每个label的key只能对应一个value。整个系统都是通过Label进行关联，从而得到真正需要操作的目标。 1.2 Kubernetes的架构和组件 K8s属于主从分布式架构，节点分为Master和Node。 1.2.1 Master节点Master作为控制节点，调度整个系统，主要由四个模块组成：APIServer、Scheduler、ControllerManager、Etcd。 APIServerAPIServer负责对外提供RESTful的KubernetesAPI服务，它是系统管理指令的统一入口，任何对资源进行增删改查的操作都要交给APIServer处理后再提交给etcd，其操作主要方法是通过Kubernetes提供的客户端工具kubectl对KubernetesAPI进行调用。 SchedulerScheduler负责调度pod到合适的Node上。如果把Scheduler看成一个黑匣子，那么它的输入是pod和多个Node组成的列表，输出是Pod和一个Node的绑定，即将这个pod部署到这个Node上。 ControllerManager如果说APIServer做的是“前台”的工作的话，那controllermanager就是负责“后台”。每个资源一般都对应有一个控制器，而controllermanager就是负责管理这些控制器。比如当我们通过APIServer创建一个pod时，这个pod创建成功后，APIServer的任务完成，而后controllermanager负责保证Pod的稳定状态。 EtcdEtcd是一个高可用的键值存储系统，K8s使用Etcd作为存储中间件，Etcd是一个高可用的键值存储系统，通过Raft一致性算法处理日志信息以保证强一致性，同时K8s中的重要数据通过Etcd进行持久化，这使得k8s框架的各组件属于无状态，可以更方便的实施分布式集群部署。 1.2.2 Node节点Node作为运行节点，用于运行管理业务的容器，主要由三个模块组成：Kubelet、Kube-proxy、Docker。 KubeletKubelet是Master在每个Node节点上面的agent在node节点是最重要的模块，它负责维护和管理该Node上面的所有容器。若容器不是通过Kubernetes创建，它并不会管理。本质上，它负责使Pod得运行状态与期望的状态一致。 Kube-proxyKube-proxy实现了Kubernetes中的服务发现和反向代理功能。反向代理方面kube-proxy支持TCP和UDP连接转发，默认基于Round Robin算法将客户端流量转发到与service对应的一组后端pod。服务发现方面kube-proxy使用etcd的watch机制，监控集群中service和endpoint对象数据的动态变化，并且维护一个service到endpoint的映射关系，从而保证了后端pod的IP变化不会对访问者造成影响。 DockerNode作为容器运行的节点，需要启动Docker服务，目前k8s也支持Rocker容器技术。 2 设计方案2.1平台部署（已完成） 平台部署包括Master节点和Node节点必要组件的安装与配置。 2.2 数据的持久化在Docker的设计实现中，容器中的数据是临时的，即当容器被销毁时，其中的数据将会丢失。如果需要持久化数据，需要使用Docker数据卷挂载宿主机上的文件或者目录到容器中。在Kubernetes中，当Pod重建的时候，数据是会丢失的，Kubernetes也是通过数据卷挂载来提供Pod数据的持久化的。Kubernetes数据卷是对Docker数据卷的扩展，Kubernetes数据卷是Pod级别的，可以用来实现Pod中容器的文件共享。 2.2.1 EmptyDir如果Pod配置了EmpyDir数据卷，在Pod的生命周期内都会存在，当Pod被分配到 Node上的时候，会在Node上创建EmptyDir数据卷，并挂载到Pod的容器中。只要Pod 存在，EmpyDir数据卷都会存在（容器删除不会导致EmpyDir数据卷丟失数据），但是如果Pod的生命周期终结（Pod被删除），EmpyDir数据卷也会被删除，并且永久丢失。EmpyDir数据卷非常适合实现Pod中容器的文件共享。Pod的设计提供了一个很好的容器组合的模型，容器之间各司其职，通过共享文件目录来完成交互，比如可以通过一个专职日志收集容器，在每个Pod中和业务容器中进行组合，来完成日志的收集和汇总。 2.2.2 网络数据卷Kubernetes提供了很多类型的数据卷以集成第三方的存储系统，包括一些非常流行的分布式文件系统，也有在IaaS平台上提供的存储支持，这些存储系统都是分布式的，通过网络共享文件系统，因此我们称这一类数据卷为网络数据卷。网络数据卷能够满足数据的持久化需求，Pod通过配置使用网络数据卷，每次Pod创建的时候都会将存储系统的远端文件目录挂载到容器中，数据卷中的数据将被水久保存，即使Pod被删除，只是除去挂载数据卷，数据卷中的数据仍然保存在存储系统中，且当新的Pod被创建的时候，仍是挂载同样的数据卷。网络数据卷包含以下几种：NFS、iSCISI、GlusterFS、RBD（Ceph Block Device）、Flocker、AWS Elastic Block Store、GCE Persistent Disk。 2.3 资源伸缩2.3.1 弹性伸缩弹性伸缩实质适应负载变化，以弹性可伸缩方式提供资源。反应到K8s当中，可以根据负载的高低动态变化通过修改Replication Controller的Pod副本数来完成，可以通过Kubectl scale命令实现。 2.3.2自动伸缩通过Replication Controller可以非常方便地实现Pod的弹性伸缩，可以在此基础上设计针对资源的自动伸缩，即基于Pod的资源使用情况，根据配置的策略自动调整Pod的副本数。在k8s中通过Horizontal Pod Autoscaler来实现Pod的自动伸缩。Horizontal Pod Autoscaler的操作对象是Replication Controller、ReplicaSet或Deployment对应的Pod，根据观察到的CPU实际使用量与用户的期望值进行比对，做出是否需要增减实例数量的决策，从而实现自动伸缩。 例如：通过kubectl run创建Replication Controller，运行一个Nginx Pod，设置其使用cpu资源为200m，并创建与之关联的Service。此时通过Horizontal Pod Autoscaler指定对应的minReplicas和maxReplicas即分别设置Pod伸缩的最小和最大副本数，并设置伸缩策略：当所有的Pod的cpu平均使用率超过了50%时候进行扩容，少于50%时进行缩容。这时候当访问量达到一定极限时，cpu使用率上升，pod数会随之扩展，从而达到自动伸缩目的。","categories":[],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://qhzxc0015.com/tags/kubernetes/"}]},{"title":"Kubernetes DNS服务的安装与配置","slug":"07. kubeDNS","date":"2017-08-15T02:45:04.000Z","updated":"2017-08-29T08:34:00.271Z","comments":true,"path":"2017/08/15/07. kubeDNS.html","link":"","permalink":"http://qhzxc0015.com/2017/08/15/07. kubeDNS.html","excerpt":"Kubernetes的DNS服务是基于SkyDNS实现的，同时又需要和API Server紧密沟通，它的基本工作方式是通过API Server监视服务创建，一旦有新的服务创建就通知SkyDNS创建一条域名解析记录。沟通API Server和SkyDNS的工作都是由Kube2Sky完成的，Kube2sky和Skydns都需要使用ETCD实现共享配置和服务发现。","text":"Kubernetes的DNS服务是基于SkyDNS实现的，同时又需要和API Server紧密沟通，它的基本工作方式是通过API Server监视服务创建，一旦有新的服务创建就通知SkyDNS创建一条域名解析记录。沟通API Server和SkyDNS的工作都是由Kube2Sky完成的，Kube2sky和Skydns都需要使用ETCD实现共享配置和服务发现。 参考文献： Kubernetes DNS服务的安装与配置 Kubernetes技术分析之DNS 部署kubernetes dns服务 Kubernetes DNS服务搭建指南 Kubernetes提供的虚拟DNS服务名为skydns，由四个组件组成： etcd：DNS存储 kube2sky：强Kubernetes Master中的service（服务）注册到etcd。 skyDNS：提供DNS域名解析服务。 healthz：提供对skydns服务的健康检查。 创建两个配置文件skydns-rc.yaml和skydns-svc.yaml： rc.yaml: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596apiVersion: v1kind: ReplicationControllermetadata: name: kube-dns namespace: kube-system labels: k8s-app: kube-dns version: v12 kubernetes.io/cluster-service: &quot;true&quot;spec: replicas: 1 selector: k8s-app: kube-dns version: v12 template: metadata: labels: k8s-app: kube-dns version: v12 kubernetes.io/cluster-service: &quot;true&quot; spec: containers: - name: etcd image: registry.cn-hangzhou.aliyuncs.com/kube_containers/etcd-amd64:3.0.17 resources: limits: cpu: 100m memory: 50Mi requests: cpu: 100m memory: 50Mi command: - /usr/local/bin/etcd - --data-dir - /tmp/data - --listen-client-urls - http://127.0.0.1:2379,http://127.0.0.1:4001 - --advertise-client-urls - http://127.0.0.1:2379,http://127.0.0.1:4001 - --initial-cluster-token - skydns-etcd volumeMounts: - name: etcd-storage mountPath: /tmp/data - name: kube2sky image: gcr.io/google_containers/kube2sky-amd64:1.15 resources: limits: cpu: 100m memory: 50Mi requests: cpu: 100m memory: 50Mi args: - --kube-master-url=http://202.193.74.179:8080 - --domain=cluster.local - name: skydns image: gcr.io/google_containers/skydns-amd64:v1.0 resources: limits: cpu: 100m memory: 50Mi requests: cpu: 100m memory: 50Mi args: - -machines=http://127.0.0.1:4001 - -addr=0.0.0.0:53 - -ns-rotate=false - -domain=cluster.local ports: - containerPort: 53 name: dns protocol: UDP - containerPort: 53 name: dns-tcp protocol: TCP - name: healthz image: gcr.io/google_containers/exechealthz-amd64:1.2 resources: limits: cpu: 10m memory: 20Mi requests: cpu: 10m memory: 20Mi args: - -cmd=nslookup kubernetes.default.svc.cluster.local 127.0.0.1 &gt;/dev/null - -port=8080 ports: - containerPort: 8080 protocol: TCP volumes: - name: etcd-storage emptyDir: &#123;&#125; dnsPolicy: Default svc.yaml: 1234567891011121314151617181920apiVersion: v1kind: Servicemetadata: name: kube-dns namespace: default labels: k8s-app: kube-dns kubernetes.io/cluster-service: &quot;true&quot; kubernetes.io/name: &quot;KubeDNS&quot;spec: selector: k8s-app: kube-dns clusterIP: 10.254.0.10 ports: - name: dns port: 53 protocol: UDP - name: dns-tcp port: 53 protocol: TCP","categories":[],"tags":[{"name":"k8s","slug":"k8s","permalink":"http://qhzxc0015.com/tags/k8s/"},{"name":"kubeDNS","slug":"kubeDNS","permalink":"http://qhzxc0015.com/tags/kubeDNS/"}]},{"title":"Kubernetes 部署","slug":"03. k8s 1.5.2","date":"2017-07-27T07:19:06.000Z","updated":"2017-08-17T07:52:11.459Z","comments":true,"path":"2017/07/27/03. k8s 1.5.2.html","link":"","permalink":"http://qhzxc0015.com/2017/07/27/03. k8s 1.5.2.html","excerpt":"本部署方法通过yum来进行自动安装,k8s版本并不是最新版,此方法简单,高效,操作性强,非常好","text":"本部署方法通过yum来进行自动安装,k8s版本并不是最新版,此方法简单,高效,操作性强,非常好 本部署为1.5.2版本:部署参考;可以根据具体需要进行版本升级:升级参考 1. 前期工作 安装环境 IP NAME 组件 OS 202.193.74.179 Master kube-apiserver,kube-scheduler,kube-controller-manager,etcd Centos 7.2 202.193.75.34 Node kube-proxy kubelet flannel Centos 7.2 202.193.75.11 Node kube-proxy kubelet flannel Centos 7.2 关闭防火墙 12sudo systemctl stop firewalld sudo systemctl disable firewalld 2. 部署环境Master 安装etcd和kubernetessudo yum -y install etcd kubernetes-master 配置文件1.修改/etc/etcd/etcd.conf 1234567891011121314151617181920212223242526272829303132333435363738394041424344# [member]ETCD_NAME=defaultETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot;#ETCD_WAL_DIR=&quot;&quot;#ETCD_SNAPSHOT_COUNT=&quot;10000&quot;#ETCD_HEARTBEAT_INTERVAL=&quot;100&quot;#ETCD_ELECTION_TIMEOUT=&quot;1000&quot;#ETCD_LISTEN_PEER_URLS=&quot;http://localhost:2380&quot;ETCD_LISTEN_CLIENT_URLS=&quot;http://0.0.0.0:2379&quot;#ETCD_MAX_SNAPSHOTS=&quot;5&quot;#ETCD_MAX_WALS=&quot;5&quot;#ETCD_CORS=&quot;&quot;##[cluster]#ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;http://localhost:2380&quot;# if you use different ETCD_NAME (e.g. test), set ETCD_INITIAL_CLUSTER value for this name, i.e. &quot;test=http://...&quot;#ETCD_INITIAL_CLUSTER=&quot;default=http://localhost:2380&quot;#ETCD_INITIAL_CLUSTER_STATE=&quot;new&quot;#ETCD_INITIAL_CLUSTER_TOKEN=&quot;etcd-cluster&quot;ETCD_ADVERTISE_CLIENT_URLS=&quot;http://localhost:2379&quot;#ETCD_DISCOVERY=&quot;&quot;#ETCD_DISCOVERY_SRV=&quot;&quot;#ETCD_DISCOVERY_FALLBACK=&quot;proxy&quot;#ETCD_DISCOVERY_PROXY=&quot;&quot;#ETCD_STRICT_RECONFIG_CHECK=&quot;false&quot;#ETCD_AUTO_COMPACTION_RETENTION=&quot;0&quot;##[proxy]#ETCD_PROXY=&quot;off&quot;#ETCD_PROXY_FAILURE_WAIT=&quot;5000&quot;#ETCD_PROXY_REFRESH_INTERVAL=&quot;30000&quot;#ETCD_PROXY_DIAL_TIMEOUT=&quot;1000&quot;#ETCD_PROXY_WRITE_TIMEOUT=&quot;5000&quot;#ETCD_PROXY_READ_TIMEOUT=&quot;0&quot;##[security]#ETCD_CERT_FILE=&quot;&quot;#ETCD_KEY_FILE=&quot;&quot;#ETCD_CLIENT_CERT_AUTH=&quot;false&quot;#ETCD_TRUSTED_CA_FILE=&quot;&quot;#ETCD_AUTO_TLS=&quot;false&quot;#ETCD_PEER_CERT_FILE=&quot;&quot;#ETCD_PEER_KEY_FILE=&quot;&quot;#ETCD_PEER_CLIENT_CERT_AUTH=&quot;false&quot; 2.修改/etc/kubernetes/apiserver 1234567891011121314151617181920212223242526#### kubernetes system config## The following values are used to configure the kube-apiserver## The address on the local server to listen to.KUBE_API_ADDRESS=&quot;--insecure-bind-address=0.0.0.0&quot;# The port on the local server to listen on.# KUBE_API_PORT=&quot;--port=8080&quot;# Port minions listen on# KUBELET_PORT=&quot;--kubelet-port=10250&quot;# Comma separated list of nodes in the etcd clusterKUBE_ETCD_SERVERS=&quot;--etcd-servers=http://127.0.0.1:2379&quot;# Address range to use for servicesKUBE_SERVICE_ADDRESSES=&quot;--service-cluster-ip-range=10.254.0.0/16&quot;# default admission control policiesKUBE_ADMISSION_CONTROL=&quot;--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ServiceAccount,ResourceQuota&quot;# Add your own!KUBE_API_ARGS=&quot;&quot; 3.修改/etc/kubernetes/controller-manager 1234567#### The following values are used to configure the kubernetes controller-manager# defaults from config and apiserver should be adequate# Add your own!KUBE_CONTROLLER_MANAGER_ARGS=&quot;--node-monitor-grace-period=10s --pod-eviction-timeout=10s&quot; 4.修改/etc/kubernetes/config 12345678910111213141516171819202122#### kubernetes system config## The following values are used to configure various aspects of all# kubernetes services, including## kube-apiserver.service# kube-controller-manager.service# kube-scheduler.service# kubelet.service# kube-proxy.service# logging to stderr means we get it in the systemd journalKUBE_LOGTOSTDERR=&quot;--logtostderr=true&quot;# journal message level, 0 is debugKUBE_LOG_LEVEL=&quot;--v=0&quot;# Should this cluster be allowed to run privileged docker containersKUBE_ALLOW_PRIV=&quot;--allow-privileged=false&quot;# How the controller-manager, scheduler, and proxy find the apiserverKUBE_MASTER=&quot;--master=http://202.193.74.179:8080&quot; 启动服务开机自启sudo systemctl enable etcd kube-apiserver kube-scheduler kube-controller-manager启动服务sudo systemctl start etcd kube-apiserver kube-scheduler kube-controller-manager 配置etcd中的网络node节点的flannel会拉取这里的配置etcdctl mk /coreos.com/network/config &#39;{&quot;Network&quot;:&quot;172.17.0.0/16&quot;}&#39; Node(minions) 安装kubernetes-node和 flannel(会自动安装docker)sudo yum -y install kubernetes-node flannel 配置文件1.修改/etc/kubernetes/config 1234567891011121314151617181920212223#### kubernetes system config## The following values are used to configure various aspects of all# kubernetes services, including## kube-apiserver.service# kube-controller-manager.service# kube-scheduler.service# kubelet.service# kube-proxy.service# logging to stderr means we get it in the systemd journalKUBE_LOGTOSTDERR=&quot;--logtostderr=true&quot;# journal message level, 0 is debugKUBE_LOG_LEVEL=&quot;--v=0&quot;# Should this cluster be allowed to run privileged docker containersKUBE_ALLOW_PRIV=&quot;--allow-privileged=false&quot;# How the controller-manager, scheduler, and proxy find the apiserver#KUBE_MASTER=&quot;--master=http://127.0.0.1:8080&quot;KUBE_MASTER=&quot;--master=http://202.193.74.179:8080&quot; 2.修改/etc/kubernetes/kubelet (注意修改每个node的IP) 1234567891011121314151617181920#### kubernetes kubelet (minion) config# The address for the info server to serve on (set to 0.0.0.0 or &quot;&quot; for all interfaces)KUBELET_ADDRESS=&quot;--address=127.0.0.1&quot;# The port for the info server to serve on# KUBELET_PORT=&quot;--port=10250&quot;# You may leave this blank to use the actual hostnameKUBELET_HOSTNAME=&quot;--hostname-override=202.193.75.11&quot;# location of the api-serverKUBELET_API_SERVER=&quot;--api-servers=http://202.193.74.179:8080&quot;# pod infrastructure containerKUBELET_POD_INFRA_CONTAINER=&quot;--pod-infra-container-image=registry.access.redhat.com/rhel7/pod-infrastructure:latest&quot;# Add your own!KUBELET_ARGS=&quot;--pod-infra-container-image=kubernetes/pause&quot; 3.修改/etc/sysconfig/flanneld 123456789101112# Flanneld configuration options # etcd url location. Point this to the server where etcd runsFLANNEL_ETCD_ENDPOINTS=&quot;http://202.193.74.179:2379&quot;# etcd config key. This is the configuration key that flannel queries# For address range assignment#FLANNEL_ETCD_PREFIX=&quot;/atomic.io/network&quot;FLANNEL_ETCD_PREFIX=&quot;/coreos.com/network&quot;# Any additional options that you want to passFLANNEL_OPTIONS=&quot; -iface=eth33&quot; 其中FLANNEL_OPTIONS=&quot; -iface=eth0&quot;的eth0是网卡名称 启动服务sudo systemctl restart flanneld dockersudo systemctl start kubelet kube-proxysudo systemctl enable flanneld kubelet kube-proxy 3. 验证在master上1234[root@179 centos]# kubectl get nodesNAME STATUS AGE202.193.75.11 Ready 29m202.193.75.34 Ready 6m 4. 附录Error 1: 12[centos@179 message_board]$ kubectl get podsNo resources found. 解决方法:参考链接,认证问题,可以跳过认证方法:12#vim /etc/kubernetes/apiserverKUBE_ADMISSION_CONTROL=&quot;--admission_control=NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota&quot;","categories":[],"tags":[{"name":"技术","slug":"技术","permalink":"http://qhzxc0015.com/tags/技术/"}]},{"title":"Markdown介绍","slug":"02. md介绍","date":"2017-07-20T13:55:06.000Z","updated":"2017-08-09T08:48:36.481Z","comments":true,"path":"2017/07/20/02. md介绍.html","link":"","permalink":"http://qhzxc0015.com/2017/07/20/02. md介绍.html","excerpt":"Markdown 语法简单，记忆负担小，纯文本，流畅书写，无违和感，各种实时渲染效果,所以被刚广泛使用","text":"Markdown 语法简单，记忆负担小，纯文本，流畅书写，无违和感，各种实时渲染效果,所以被刚广泛使用 优点 语法简单，记忆负担小，纯文本，流畅书写，无违和感，各种实时渲染效果。 markdown是为那些需要经常码东西并且进行文字排版的、对码字手速和排版顺畅度有要求的人群设计的，他们希望用键盘把文字内容啪啪啪地打出来后就已经排版好了，最好从头到尾都不要使用鼠标。这些人包括经常需要写文档的码农、博客写手、网站小编、出版业人士等等。 通常情况下，网络上需要进行大量文字输入的地方都可以通过所见即所得的方式排版 再强调一下实时的渲染效果。无论新手老手写 Markdown 的时候最担心的是不知道自己写的对不对，最后渲染效果是不是准确无误。就好象写完代码你一定要自己测试一下才放心，写 Markdown 就是在写代码，实时的渲染效果就是在做测试，这就是为什么网络上有那么多左右两屏带实时渲染的 Markdown 工具的原因（另一个原因是宽屏）1 公式,[^LaTeX]: 支持 LaTeX 编辑显示支持，例如：$\\sum_{i=1}^n a_i=0$， 访问 MathJax $$ x = \\dfrac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} $$ $$\\Gamma(z) = \\int_0^\\infty t^{z-1}e^{-t}dt\\,.$$ $$ \\begin{matrix} 1 &amp; x &amp; x^2 \\ 1 &amp; y &amp; y^2 \\ 1 &amp; z &amp; z^2 \\ \\end{matrix}$$ $$ \\left[ \\begin{array}{cc|c} 1&amp;2&amp;3\\ 4&amp;5&amp;6 \\end{array}\\right] $$ \\begin{align}\\sqrt{37} &amp; = \\sqrt{\\frac{73^2-1}{12^2}} \\ &amp; = \\sqrt{\\frac{73^2}{12^2}\\cdot\\frac{73^2-1}{73^2}} \\ &amp; = \\sqrt{\\frac{73^2}{12^2}}\\sqrt{\\frac{73^2-1}{73^2}} \\ &amp; = \\frac{73}{12}\\sqrt{1 - \\frac{1}{73^2}} \\ &amp; \\approx \\frac{73}{12}\\left(1 - \\frac{1}{2\\cdot73^2}\\right)\\end{align} $ \\newcommand{\\SES}[3]{ 0 \\to #1 \\to #2 \\to #3 \\to 0 } $ 表格| 1 | 2 | 3 | 4 || —- | —: | :–: | —- || 1 | 1 | 1 | 1 | Item Value Computer \\$1600 Phone \\$12 Pipe \\$1 1.这个是脚注 ↩","categories":[],"tags":[{"name":"技术","slug":"技术","permalink":"http://qhzxc0015.com/tags/技术/"}]},{"title":"hexo基本配置","slug":"01. hexo","date":"2017-07-19T13:55:06.000Z","updated":"2017-08-09T08:56:16.305Z","comments":true,"path":"2017/07/19/01. hexo.html","link":"","permalink":"http://qhzxc0015.com/2017/07/19/01. hexo.html","excerpt":"","text":"这里不错吧,是吧,是吧,来来来,看一下hexo啦~ 常用命令 1234567891011121314hexo clean #清除PUBLIC和编译文件hexo generate #编译网站目录hexo deploy #同步到GIT 或者CODINGnpm install &lt;plugin-name&gt; --save #安装npm update #升级npm uninstall &lt;plugin-name&gt; #卸载hexo new”postName” #新建文章 #存放在主目录的source下的POST目录下hexo new page”pageName” #新建页面hexo generate #生成静态页面至public目录hexo server #开启预览访问端口（默认端口4000，’ctrl + c’关闭server）hexo deploy #将.deploy目录部署到GitHubhexo help # 查看帮助hexo version #查看Hexo的版本 主目录 12345678910├── .deploy #需要部署的文件├── node_modules #Hexo插件├── public #生成的静态网页文件├── scaffolds #模板├── source #博客正文和其他源文件, 404 favicon CNAME 等都应该放在这里| ├── _drafts #草稿| └── _posts #文章├── themes #主题├── _config.yml #全局配置文件└── package.json 主题目录 123456789101112131415161718├── languages #国际化| ├── default.yml #默认| └── zh-CN.yml #中文├── layout #布局| ├── _partial #局部的布局| └── _widget #小挂件的布局├── script #js脚本├── source #源代码文件| ├── css #CSS| | ├── _base #基础CSS| | ├── _partial #局部CSS| | ├── fonts #字体| | ├── images #图片| | └── style.styl #style.css| ├── fancybox #fancybox| └── js #js├── _config.yml #主题配置文件└── README.md #主题介绍 以上目录中常用的有: scaffolds source themes config.yml 根配置文件:_config.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071# Site #站点信息title: lmintlcx #标题subtitle: 做人不卖萌跟咸鱼有什么区别 #副标题description: lmintlcx lm lcx blog #描述author: lmintlcx #作者language: zh-Hans #语言timezone: Asia/Shanghai #时区# URL #链接格式url: http://joryhe.coding.me/ #网址root: / #根目录permalink: post/:title.html #文章的链接格式permalink_defaults:# Directory #目录source_dir: source #源文件public_dir: public #生成的网页文件tag_dir: tags #标签archive_dir: archives #归档category_dir: categories #分类code_dir: downloads/codei18n_dir: :lang #国际化skip_render:# Writing #写作new_post_name: :title.md #新文章标题default_layout: post #默认模板titlecase: false #标题转换成大写external_link: true #新标签页里打开连接filename_case: 0render_drafts: falsepost_asset_folder: falserelative_link: falsefuture: truehighlight: #语法高亮 enable: true line_number: false #显示行号 auto_detect: true tab_replace:# Category &amp; Tag #分类和标签default_category: uncategorized #默认分类category_map:tag_map:# Date / Time format #日期时间格式date_format: YYYY-MM-DDtime_format: HH:mm:ss# Pagination #分页per_page: 20 #每页文章数, 设置成 0 禁用分页pagination_dir: page# Extensions #插件和主题## 插件: http://hexo.io/plugins/## 主题: http://hexo.io/themes/theme: next# Deployment #部署, joryhe是我的用户名, 同时发布GitHub deploy: type: git repo: github: github: git@github.com:joryhe/joryhe.github.io.git,master# Disqus #Disqus评论系统disqus_shortname: plugins: #插件，例如生成 RSS 和站点地图的- hexo-generator-feed- hexo-generator-sitemap 主题配置文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677menu: #菜单 home: / #首页 archives: /archives #归档 about: /about #关于 #commonweal: /404.html #公益404 #tags: /tags #标签 #categories: /categories #分类## 经典介绍配置# 小图标favicon: /favicon.ico# 默认关键词keywords: # 留空使用默认的, false 禁用, 也可以写指定的地址rss:# Icon fonts# default | linecons | fifty-shades | feathericon_font: default# 代码高亮主题 https://github.com/chriskempson/tomorrow-theme# normal | night | night eighties | night blue | night brighthighlight_theme: normal# MathJax Support #数学公式mathjax: true# Schemes #启用主题中的主题Mistscheme: Mist# 侧边栏# - post 只在文章页面显示# - always 所有页面显示# - hide 隐藏sidebar: always# 自动滚动到&quot;阅读更多&quot;标记的下面scroll_to_more: true# 自动给目录添加序号toc_list_number: true# 自动截取摘要auto_excerpt: enable: false length: 150# Lato 字体use_font_lato: true# Make duoshuo show UA# user_id must NOT be null when admin_enable is true!# you can visit http://dev.duoshuo.com get duoshuo user id.duoshuo_info: ua_enable: true admin_enable: false user_id: 0 #admin_nickname: ROOT## DO NOT EDIT THE FOLLOWING SETTINGS## UNLESS YOU KNOW WHAT YOU ARE DOING# 动画use_motion: true# Fancybox 看图插件fancybox: true# Static filesvendors: vendorscss: cssjs: jsimages: images# Theme versionversion: 0.4.5.1","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://qhzxc0015.com/tags/hexo/"}]}]}