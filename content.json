{"meta":{"title":"thk_days","subtitle":"I think that that that that that article wrote on the blog was wrong.","description":"程序猿 | 熬夜猫 | 次元狗","author":"zxc","url":"http://qhzxc0015.com"},"pages":[{"title":"About","date":"2017-10-10T16:00:00.000Z","updated":"2017-10-12T07:00:43.347Z","comments":true,"path":"about/index.html","permalink":"http://qhzxc0015.com/about/index.html","excerpt":"","text":"hello world Pika Pika ~ Pikachu ~ is here. If Click Ghost , emmm... If you are single person (Oh,No)!, Please Click this or this or or this! Ok,ok~ haha ~ pr pr pr ~"},{"title":"categories","date":"2017-08-06T21:44:46.000Z","updated":"2017-08-06T21:52:18.927Z","comments":true,"path":"categories/index.html","permalink":"http://qhzxc0015.com/categories/index.html","excerpt":"","text":""},{"title":"project","date":"2017-08-07T02:21:43.000Z","updated":"2017-08-07T17:08:27.067Z","comments":true,"path":"project/index.html","permalink":"http://qhzxc0015.com/project/index.html","excerpt":"","text":""},{"title":"guestbook","date":"2017-08-06T18:22:45.000Z","updated":"2017-08-07T10:33:37.106Z","comments":true,"path":"guestbook/index.html","permalink":"http://qhzxc0015.com/guestbook/index.html","excerpt":"","text":""},{"title":"tags","date":"2017-07-21T12:44:19.000Z","updated":"2017-07-21T12:56:21.358Z","comments":true,"path":"tags/index.html","permalink":"http://qhzxc0015.com/tags/index.html","excerpt":"","text":""},{"title":"photos","date":"2017-08-07T01:36:11.000Z","updated":"2017-11-22T16:13:35.709Z","comments":true,"path":"photos/index.html","permalink":"http://qhzxc0015.com/photos/index.html","excerpt":"","text":"$(\"#Thplayer\").thplayer({ title: \"稻香\", author: \"周杰伦\", cover: \"http://p4.music.126.net/gYwk-n_UWAtOfDZBEV04dQ==/7699879929738059.jpg\", music: \"http://ou9i51fe5.bkt.clouddn.com/music/%E7%A8%BB%E9%A6%99.mp3\" }); Welcom 你好啊，欢迎来到小世界， 这里很小，让我带你逛逛。 跟我走吧 那段奋不顾身的日子，叫青春 一直觉得自己的成长是一瞬间的。没有漫长的打坐，也没有光影明灭的交替， 忽然有那么一天，就被时光拽到了成人的世界，至此，泾渭分明。 喜欢你已超过两分钟，不能撤回 要多活一些岁月才知道，跟某些人之间永远没法斩钉截铁画下一个句号。 像少年一样无赖，像中年一样去爱 时间从未走远，在那些始终和时间赛跑的人身上。 每一天落寞的阳光变成防腐剂，每一日沉睡的星空覆上保护膜，任何外界的干扰，都成为独自前进的坚定力量。而这种力量，历久弥新，终于成为你生命中不可或缺的一部分。 我们拼命变好，是因为心里住着不想辜负的人 ... One L Details Two O Details Three V Details Four E Details 故事 还记得让你突然感到非常舒服的那些时刻吗？ 1. 高中晚自习，突然停电了。老师出了教室查看，顿时大家像起了化学反应，一下子从安静变的沸腾。等到老师回来沮丧的说，一时修不好，晚自习不上了。整个楼顿时传来尖叫声。 2. 雨淅淅沥沥的下着，周末在家一天没有洗脸，上午打扫房间洗衣服，到了中午叫了外卖吃了饱饱的午餐，困意上来。在干净的小窝里，舒心的听着雨打芭蕉般的声音，缓缓睡去，心宁静的仿佛世界温柔的和你一起静谧下去。 3. 忙碌了一整年，拉着行李回到家。敲开门，先是妈妈大大的拥抱，看到门口已经准备好我的专属拖鞋。洗手换上家里干净舒适的睡衣，餐厅一大桌子自己爱吃的菜。舒舒服服的大快朵颐一番，妈妈在旁边笑着看着我，新闻联播的序幕曲从客厅里传来。 4. 喜欢上一个人，她笑起来非常温柔可爱。找各种理由见面，内心很兴奋。一起看电影，心里砰砰跳个不停，她的手就在旁边，悄悄伸手拉住，没有任何言语却紧张到僵硬的像个雕塑凝固在那。 5. 夏天午觉刚睡醒，目光呆滞，智商减半，但内心深处知道，自己将要满血复活。于是坐在那里，看自己一点点的变身。 6. 今天是周五。 Twitter Facebook Instagram LinkedIn Email"}],"posts":[{"title":"kubernetes for Elasticsearch","slug":"08.k8s for es","date":"2017-12-01T22:56:03.000Z","updated":"2017-12-03T17:28:24.814Z","comments":true,"path":"2017/12/02/08.k8s for es.html","link":"","permalink":"http://qhzxc0015.com/2017/12/02/08.k8s for es.html","excerpt":"ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，其部署简单扩展方便，所以用k8s+es实践。","text":"ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，其部署简单扩展方便，所以用k8s+es实践。 参考文献： 使用k8s编排ElasticSearch集群 Elasticsearch for Kubernetes CentOS7.2使用yum安装kubernetes ETCD系列 1. Kubernetes搭建1.1 准备工作1.1.1 关闭防火墙12systemctl stop firewalld systemctl disable firewalld 1.1.2 安装NTP123yum -y install ntp systemctl start ntpd systemctl enable ntpd 1.1.3 禁用selinux执行命令：vim /etc/selinux/config12#SELINUX=enforcing SELINUX=disabled 2.2 搭建kubernetes2.1.1 环境配置以及角色 IP Hosts Role 202.193.74.179 master,etcd etcd kube-apiserver kube-scheduler kube-controller-manage flannel 202.193.75.80 node1 docker kube-proxy kubelet flannel 202.193.75.34 node2 docker kube-proxy kubelet flannel 2.1.2 安装etcd etcd用于服务发现和服务注册，解决客户端如何知道多节点上服务的IP地址和端口问题。Etcd组件作为一个高可用强一致性的服务发现存储仓库,etcd服务需要提供kubernetes集群的所有节点，因此需要监听于可用于外部通信的地址。 安装步骤如下执行命令：yum install -y etcd检测安装：rpm -ql etcd1234567891011121314[centos@179 es]$ rpm -ql etcd/etc/etcd/etc/etcd/etcd.conf/usr/bin/etcd/usr/bin/etcdctl/usr/lib/systemd/system/etcd.service/usr/share/doc/etcd-3.1.9/usr/share/doc/etcd-3.1.9/CONTRIBUTING.md/usr/share/doc/etcd-3.1.9/README.md/usr/share/doc/etcd-3.1.9/ROADMAP.md/usr/share/doc/etcd-3.1.9/glide.lock/usr/share/licenses/etcd-3.1.9/usr/share/licenses/etcd-3.1.9/LICENSE/var/lib/etcd 对其中/etc/etcd/etcd.conf文件进行配置sudo vim /etc/etcd/etcd.conf1234567891011121314151617181920212223242526272829303132333435363738394041424344# [member]ETCD_NAME=defaultETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot;#ETCD_WAL_DIR=&quot;&quot;#ETCD_SNAPSHOT_COUNT=&quot;10000&quot;#ETCD_HEARTBEAT_INTERVAL=&quot;100&quot;#ETCD_ELECTION_TIMEOUT=&quot;1000&quot;ETCD_LISTEN_PEER_URLS=&quot;http://master:2380&quot;ETCD_LISTEN_CLIENT_URLS=&quot;http://master:2379&quot;#ETCD_MAX_SNAPSHOTS=&quot;5&quot;#ETCD_MAX_WALS=&quot;5&quot;#ETCD_CORS=&quot;&quot;##[cluster]ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;http://master:2380&quot;# if you use different ETCD_NAME (e.g. test), set ETCD_INITIAL_CLUSTER value for this name, i.e. &quot;test=http://...&quot;ETCD_INITIAL_CLUSTER=&quot;default=http://etcd:2380&quot;#ETCD_INITIAL_CLUSTER_STATE=&quot;new&quot;#ETCD_INITIAL_CLUSTER_TOKEN=&quot;etcd-cluster&quot;ETCD_ADVERTISE_CLIENT_URLS=&quot;http://master:2379&quot;#ETCD_DISCOVERY=&quot;&quot;#ETCD_DISCOVERY_SRV=&quot;&quot;#ETCD_DISCOVERY_FALLBACK=&quot;proxy&quot;#ETCD_DISCOVERY_PROXY=&quot;&quot;#ETCD_STRICT_RECONFIG_CHECK=&quot;false&quot;#ETCD_AUTO_COMPACTION_RETENTION=&quot;0&quot;##[proxy]#ETCD_PROXY=&quot;off&quot;#ETCD_PROXY_FAILURE_WAIT=&quot;5000&quot;#ETCD_PROXY_REFRESH_INTERVAL=&quot;30000&quot;#ETCD_PROXY_DIAL_TIMEOUT=&quot;1000&quot;#ETCD_PROXY_WRITE_TIMEOUT=&quot;5000&quot;#ETCD_PROXY_READ_TIMEOUT=&quot;0&quot;##[security]#ETCD_CERT_FILE=&quot;&quot;#ETCD_KEY_FILE=&quot;&quot;#ETCD_CLIENT_CERT_AUTH=&quot;false&quot;#ETCD_TRUSTED_CA_FILE=&quot;&quot;#ETCD_AUTO_TLS=&quot;false&quot;#ETCD_PEER_CERT_FILE=&quot;&quot;#ETCD_PEER_KEY_FILE=&quot;&quot;#ETCD_PEER_CLIENT_CERT_AUTH=&quot;false&quot; 配置完毕，重启服务执行命令：sudo systemctl restart etcd查看集群健康程度：etcdctl -C http://master:2379 cluster-health12member 8e9e05c52164694d is healthy: got healthy result from http://master:2379cluster is healthy 创建目录：etcdctl -C http://master:2379 mkdir /testdir查看目录：etcdctl -C http://master:2379 ls给newkey一个helloetcd值：etcdctl -C http://master:2379 mk /testdir/newkey helloetcd 2.1.3 安装kubernetes master节点查看所有kubernetes安装包:yum list all kubernetes* 12345678910已加载插件：fastestmirror, langpacksDetermining fastest mirrors * base: centos.ustc.edu.cn * extras: mirrors.sohu.com * updates: mirrors.aliyun.comkubernetes-client.x86_64 1.5.2-0.7.git269f928.el7 @extraskubernetes-node.x86_64 1.5.2-0.7.git269f928.el7 @extraskubernetes.x86_64 1.5.2-0.7.git269f928.el7 extras kubernetes-master.x86_64 1.5.2-0.7.git269f928.el7 extras kubernetes-unit-test.x86_64 1.5.2-0.7.git269f928.el7 extras 12345678910已加载插件：fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.nwsuaf.edu.cn * extras: ftp.sjtu.edu.cn * updates: mirrors.aliyun.comkubernetes-client.x86_64 1.5.2-0.7.git269f928.el7 kubernetes-master.x86_64 1.5.2-0.7.git269f928.el7 kubernetes.x86_64 1.5.2-0.7.git269f928.el7 kubernetes-node.x86_64 1.5.2-0.7.git269f928.el7 kubernetes-unit-test.x86_64 1.5.2-0.7.git269f928.el7 安装master：sudo yum install -y kubernetes-master安装kubernetes-master的时候也安装了kubernetes-client。查看安全：rpm -ql kubernetes-master123456789101112131415161718192021222324/etc/kubernetes/etc/kubernetes/apiserver/etc/kubernetes/config/etc/kubernetes/controller-manager/etc/kubernetes/scheduler/run/kubernetes/usr/bin/hyperkube/usr/bin/kube-apiserver/usr/bin/kube-controller-manager/usr/bin/kube-scheduler/usr/lib/systemd/system/kube-apiserver.service/usr/lib/systemd/system/kube-controller-manager.service/usr/lib/systemd/system/kube-scheduler.service/usr/lib/tmpfiles.d/kubernetes.conf/usr/share/doc/kubernetes-master-1.5.2/usr/share/doc/kubernetes-master-1.5.2/CHANGELOG.md/usr/share/doc/kubernetes-master-1.5.2/CONTRIBUTING.md/usr/share/doc/kubernetes-master-1.5.2/README.md/usr/share/doc/kubernetes-master-1.5.2/code-of-conduct.md/usr/share/licenses/kubernetes-master-1.5.2/usr/share/licenses/kubernetes-master-1.5.2/LICENSE/usr/share/man/man1/kube-apiserver.1.gz/usr/share/man/man1/kube-controller-manager.1.gz/usr/share/man/man1/kube-scheduler.1.gz 查看安装：rpm -ql kubernetes-client1234567891011/usr/bin/hyperkube/usr/bin/kubectl/usr/share/bash-completion/completions/kubectl/usr/share/doc/kubernetes-client-1.5.2/usr/share/doc/kubernetes-client-1.5.2/CHANGELOG.md/usr/share/doc/kubernetes-client-1.5.2/CONTRIBUTING.md/usr/share/doc/kubernetes-client-1.5.2/README.md/usr/share/doc/kubernetes-client-1.5.2/code-of-conduct.md/usr/share/licenses/kubernetes-client-1.5.2/usr/share/licenses/kubernetes-client-1.5.2/LICENSE..... 对其中的apiserver进行修改sudo vim apiserver1234567891011121314151617181920#### kubernetes system config## The following values are used to configure the kube-apiserver## The address on the local server to listen to.KUBE_API_ADDRESS=&quot;--insecure-bind-address=0.0.0.0&quot;# The port on the local server to listen on.# KUBE_API_PORT=&quot;--port=8080&quot;# Port minions listen on# KUBELET_PORT=&quot;--kubelet_port=10250&quot;# Comma separated list of nodes in the etcd clusterKUBE_ETCD_SERVERS=&quot;--etcd-servers=http://etcd:2379&quot;# Address range to use for servicesKUBE_SERVICE_ADDRESSES=&quot;--service-cluster-ip-range=10.254.0.0/16&quot;# default admission control policies# KUBE_ADMISSION_CONTROL=&quot;--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ServiceAccount,ResourceQuota&quot;KUBE_ADMISSION_CONTROL=&quot;--admission_control=NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota&quot;# Add your own!KUBE_API_ARGS=&quot;&quot; 注意：KUBE_ADMISSION_CONTROL选项里删除ServiceAccount选项。不用帐号密码认证，麻烦。对config进行修改sudo vim config 12345678910111213141516171819#### kubernetes system config## The following values are used to configure various aspects of all# kubernetes services, including## kube-apiserver.service# kube-controller-manager.service# kube-scheduler.service# kubelet.service# kube-proxy.service# logging to stderr means we get it in the systemd journalKUBE_LOGTOSTDERR=&quot;--logtostderr=true&quot;# journal message level, 0 is debugKUBE_LOG_LEVEL=&quot;--v=0&quot;# Should this cluster be allowed to run privileged docker containersKUBE_ALLOW_PRIV=&quot;--allow-privileged=false&quot;# How the controller-manager, scheduler, and proxy find the apiserverKUBE_MASTER=&quot;--master=http://master:8080&quot; 配置完成，启动服务kubernetes-mastersystemctl start kube-apiserver.service kube-controller-manager.service kube-scheduler.service node节点 1.docker安装：yum install -y docker2.kubernetes-node安装：yum install -y kubernetes-node查看安装rpm -ql kubernetes-node ​ 12345678910111213141516171819202122/etc/kubernetes/etc/kubernetes/config/etc/kubernetes/kubelet/etc/kubernetes/proxy/etc/systemd/system.conf.d/kubernetes-accounting.conf/run/kubernetes/usr/bin/hyperkube/usr/bin/kube-proxy/usr/bin/kubelet/usr/lib/systemd/system/kube-proxy.service/usr/lib/systemd/system/kubelet.service/usr/lib/tmpfiles.d/kubernetes.conf/usr/share/doc/kubernetes-node-1.5.2/usr/share/doc/kubernetes-node-1.5.2/CHANGELOG.md/usr/share/doc/kubernetes-node-1.5.2/CONTRIBUTING.md/usr/share/doc/kubernetes-node-1.5.2/README.md/usr/share/doc/kubernetes-node-1.5.2/code-of-conduct.md/usr/share/licenses/kubernetes-node-1.5.2/usr/share/licenses/kubernetes-node-1.5.2/LICENSE/usr/share/man/man1/kube-proxy.1.gz/usr/share/man/man1/kubelet.1.gz/var/lib/kubelet 修改kubelet1234567891011121314151617181920#### kubernetes kubelet (minion) config# The address for the info server to serve on (set to 0.0.0.0 or &quot;&quot; for all interfaces)KUBELET_ADDRESS=&quot;--address=0.0.0.0&quot;# The port for the info server to serve on# KUBELET_PORT=&quot;--port=10250&quot;# You may leave this blank to use the actual hostnameKUBELET_HOSTNAME=&quot;--hostname-override=node1&quot;# location of the api-serverKUBELET_API_SERVER=&quot;--api-servers=http://master:8080&quot;# pod infrastructure containerKUBELET_POD_INFRA_CONTAINER=&quot;--pod-infra-container-image=registry.access.redhat.com/rhel7/pod-infrastructure:latest&quot;# Add your own!KUBELET_ARGS=&quot;--pod-infra-container-image=kubernetes/pause&quot; 修改config1234567891011121314151617181920212223#### kubernetes system config## The following values are used to configure various aspects of all# kubernetes services, including## kube-apiserver.service# kube-controller-manager.service# kube-scheduler.service# kubelet.service# kube-proxy.service# logging to stderr means we get it in the systemd journalKUBE_LOGTOSTDERR=&quot;--logtostderr=true&quot;# journal message level, 0 is debugKUBE_LOG_LEVEL=&quot;--v=0&quot;# Should this cluster be allowed to run privileged docker containersKUBE_ALLOW_PRIV=&quot;--allow-privileged=false&quot;# How the controller-manager, scheduler, and proxy find the apiserver#KUBE_MASTER=&quot;--master=http://127.0.0.1:8080&quot;KUBE_MASTER=&quot;--master=http://master:8080&quot; 启动服务：systemctl start kubelet.service kube-proxy.service添加节点，config不变，只需修改kubelet启动服务后可以查看端口netstat -tln12345678910111213141516Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 127.0.0.1:10248 0.0.0.0:* LISTEN tcp 0 0 127.0.0.1:10249 0.0.0.0:* LISTEN tcp 0 0 192.168.122.1:53 0.0.0.0:* LISTEN tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN tcp 0 0 127.0.0.1:631 0.0.0.0:* LISTEN tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN tcp6 0 0 :::10250 :::* LISTEN tcp6 0 0 :::10255 :::* LISTEN tcp6 0 0 :::22 :::* LISTEN tcp6 0 0 ::1:631 :::* LISTEN tcp6 0 0 :::31480 :::* LISTEN tcp6 0 0 ::1:25 :::* LISTEN tcp6 0 0 :::31451 :::* LISTEN tcp6 0 0 :::4194 :::* LISTEN tcp6 0 0 :::31685 :::* LISTEN 其中4194位cAdvisor服务 2.1.3 安装flannel k8s的网络管理用flannel网络。所以三个节点(master,node1,node2)都要装。 执行命令：yum install -y flannel查看安装：rpm -ql flannel123456789101112131415/run/flannel/usr/bin/flanneld/usr/bin/flanneld-start/usr/lib/systemd/system/docker.service.d/flannel.conf/usr/lib/systemd/system/flanneld.service/usr/lib/tmpfiles.d/flannel.conf/usr/libexec/flannel/usr/libexec/flannel/mk-docker-opts.sh/usr/share/doc/flannel-0.7.1/usr/share/doc/flannel-0.7.1/CONTRIBUTING.md/usr/share/doc/flannel-0.7.1/DCO/usr/share/doc/flannel-0.7.1/LICENSE/usr/share/doc/flannel-0.7.1/MAINTAINERS/usr/share/doc/flannel-0.7.1/NOTICE/usr/share/doc/flannel-0.7.1/README.md sudo vim /etc/sysconfig/flanneld1234567891011# Flanneld configuration options # etcd url location. Point this to the server where etcd runsFLANNEL_ETCD_ENDPOINTS=&quot;http://etcd:2379&quot;# etcd config key. This is the configuration key that flannel queries# For address range assignmentFLANNEL_ETCD_PREFIX=&quot;/coreos.com/network&quot;# Any additional options that you want to passFANNEL_OPTIONS=&quot; -iface=ens33&quot; master需要etcd讲键值存入：etcdctl -C http://etcd1:2379 mk /ilinux.io/network/config &#39;{&quot;Network&quot;:&quot;10.7.0.0/16&quot;}&#39;启动flannel服务：systemcl start flanneld.service通过ifconfig进行查看，这时docker0与flannel0处于同一网段12345678910111213141516171819202122232425docker0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1472 inet 10.7.8.1 netmask 255.255.255.0 broadcast 0.0.0.0 inet6 fe80::42:97ff:fe39:3861 prefixlen 64 scopeid 0x20&lt;link&gt; ether 02:42:97:39:38:61 txqueuelen 0 (Ethernet) RX packets 53 bytes 3474 (3.3 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 46 bytes 5360 (5.2 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0ens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 202.193.75.34 netmask 255.255.254.0 broadcast 202.193.75.255 inet6 fe80::20c:29ff:fe65:c10f prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:65:c1:0f txqueuelen 1000 (Ethernet) RX packets 34213307 bytes 4678823447 (4.3 GiB) RX errors 0 dropped 2 overruns 0 frame 0 TX packets 1419255 bytes 781178180 (744.9 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0flannel0: flags=4305&lt;UP,POINTOPOINT,RUNNING,NOARP,MULTICAST&gt; mtu 1472 inet 10.7.8.0 netmask 255.255.0.0 destination 10.7.8.0 unspec 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00 txqueuelen 500 (UNSPEC) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 3.1 搭建es3.1.1 拉取镜像执行命令：sudo docker docker.io/kayrus/docker-elasticsearch-kubernetes:1.7.1 部署文件es-rc.yaml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051apiVersion: v1kind: ReplicationControllermetadata: name: es labels: component: elasticsearchspec: replicas: 1 template: metadata: labels: component: elasticsearch spec: serviceAccount: elasticsearch containers: - name: es securityContext: capabilities: add: - IPC_LOCK image: docker.io/kayrus/docker-elasticsearch-kubernetes:1.7.1 env: - name: KUBERNETES_CA_CERTIFICATE_FILE value: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt - name: NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace - name: &quot;CLUSTER_NAME&quot; value: &quot;myesdb&quot; - name: &quot;DISCOVERY_SERVICE&quot; value: &quot;elasticsearch&quot; - name: NODE_MASTER value: &quot;true&quot; - name: NODE_DATA value: &quot;true&quot; - name: HTTP_ENABLE value: &quot;true&quot; ports: - containerPort: 9200 name: http protocol: TCP - containerPort: 9300 name: transport protocol: TCP volumeMounts: - mountPath: /data name: storage volumes: - name: storage emptyDir: &#123;&#125; es-svc.yaml1234567891011121314151617apiVersion: v1kind: Servicemetadata: name: elasticsearch labels: component: elasticsearchspec: type: LoadBalancer selector: component: elasticsearch ports: - name: http port: 9200 protocol: TCP - name: transport port: 9300 protocol: TCP service-account.yaml1234apiVersion: v1kind: ServiceAccountmetadata: name: elasticsearch 部署指令：kubectl create -f .查看工作：kubectl get pods123[centos@179 EFK]$ kubectl get podsNAME READY STATUS RESTARTS AGEes-3c69r 1/1 Running 0 1d 查看日志：kubectl logs es-3c69r123456789101112[centos@179 EFK]$ kubectl logs es-3c69r[2017-12-01 22:50:17,664][INFO ][node ] [Legion] version[1.7.1], pid[1], build[b88f43f/2015-07-29T09:54:16Z][2017-12-01 22:50:17,664][INFO ][node ] [Legion] initializing ...[2017-12-01 22:50:17,811][INFO ][plugins ] [Legion] loaded [], sites [][2017-12-01 22:50:17,877][INFO ][env ] [Legion] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [9.7gb], net total_space [9.9gb], types [rootfs][2017-12-01 22:50:20,781][INFO ][node ] [Legion] initialized[2017-12-01 22:50:20,783][INFO ][node ] [Legion] starting ...[2017-12-01 22:50:21,052][INFO ][transport ] [Legion] bound_address &#123;inet[/0:0:0:0:0:0:0:0:9300]&#125;, publish_address &#123;inet[/10.7.28.4:9300]&#125;[2017-12-01 22:50:21,088][INFO ][discovery ] [Legion] elasticsearch/tfcW-qCYTa6Eq27G-ts6-Q[2017-12-01 22:50:24,172][INFO ][cluster.service ] [Legion] detected_master [Lockdown][TepMZvL3T_O5Yu2YeMPn_A][es-qg67z][inet[/10.7.28.2:9300]], added &#123;[Lockdown][TepMZvL3T_O5Yu2YeMPn_A][es-qg67z][inet[/10.7.28.2:9300]],&#125;, reason: zen-disco-receive(from master [[Lockdown][TepMZvL3T_O5Yu2YeMPn_A][es-qg67z][inet[/10.7.28.2:9300]]])[2017-12-01 22:50:24,223][INFO ][http ] [Legion] bound_address &#123;inet[/0:0:0:0:0:0:0:0:9200]&#125;, publish_address &#123;inet[/10.7.28.4:9200]&#125;[2017-12-01 22:50:24,223][INFO ][node ] [Legion] started 扩展节点Scale命令：kubectl scale --replicas=3 rc es12345[centos@179 EFK]$ kubectl get podsNAME READY STATUS RESTARTS AGEes-3c69r 1/1 Running 0 1des-qg67z 1/1 Running 0 1des-z11hm 1/1 Running 0 1d 查看日志1234567891011121314[centos@179 EFK]$ kubectl logs es-qg67z[2017-12-01 22:49:45,616][INFO ][node ] [Lockdown] version[1.7.1], pid[1], build[b88f43f/2015-07-29T09:54:16Z][2017-12-01 22:49:45,617][INFO ][node ] [Lockdown] initializing ...[2017-12-01 22:49:45,738][INFO ][plugins ] [Lockdown] loaded [], sites [][2017-12-01 22:49:45,799][INFO ][env ] [Lockdown] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [9.7gb], net total_space [9.9gb], types [rootfs][2017-12-01 22:49:48,226][INFO ][node ] [Lockdown] initialized[2017-12-01 22:49:48,227][INFO ][node ] [Lockdown] starting ...[2017-12-01 22:49:48,397][INFO ][transport ] [Lockdown] bound_address &#123;inet[/0:0:0:0:0:0:0:0:9300]&#125;, publish_address &#123;inet[/10.7.28.2:9300]&#125;[2017-12-01 22:49:48,441][INFO ][discovery ] [Lockdown] elasticsearch/TepMZvL3T_O5Yu2YeMPn_A[2017-12-01 22:49:52,221][INFO ][cluster.service ] [Lockdown] new_master [Lockdown][TepMZvL3T_O5Yu2YeMPn_A][es-qg67z][inet[/10.7.28.2:9300]], reason: zen-disco-join (elected_as_master)[2017-12-01 22:49:52,272][INFO ][http ] [Lockdown] bound_address &#123;inet[/0:0:0:0:0:0:0:0:9200]&#125;, publish_address &#123;inet[/10.7.28.2:9200]&#125;[2017-12-01 22:49:52,273][INFO ][node ] [Lockdown] started[2017-12-01 22:49:52,291][INFO ][gateway ] [Lockdown] recovered [0] indices into cluster_state[2017-12-01 22:50:24,144][INFO ][cluster.service ] [Lockdown] added &#123;[Legion][tfcW-qCYTa6Eq27G-ts6-Q][es-3c69r][inet[/10.7.28.4:9300]],&#125;, reason: zen-disco-receive(join from node[[Legion][tfcW-qCYTa6Eq27G-ts6-Q][es-3c69r][inet[/10.7.28.4:9300]]]) 查看服务：kubectl get svc123[centos@179 EFK]$ kubectl get svcNAME CLUSTER-IP EXTERNAL-IP PORT(S) AGEelasticsearch 10.254.156.16 &lt;pending&gt; 9200:31451/TCP,9300:31685/TCP 1d 通过访问31451可以12345678910111213141516[centos@179 EFK]$ curl node2:31451/_cluster/health?pretty&#123; &quot;cluster_name&quot; : &quot;elasticsearch&quot;, &quot;status&quot; : &quot;green&quot;, &quot;timed_out&quot; : false, &quot;number_of_nodes&quot; : 2, &quot;number_of_data_nodes&quot; : 2, &quot;active_primary_shards&quot; : 0, &quot;active_shards&quot; : 0, &quot;relocating_shards&quot; : 0, &quot;initializing_shards&quot; : 0, &quot;unassigned_shards&quot; : 0, &quot;delayed_unassigned_shards&quot; : 0, &quot;number_of_pending_tasks&quot; : 0, &quot;number_of_in_flight_fetch&quot; : 0&#125;","categories":[],"tags":[{"name":"kubernetes Elasticsearch","slug":"kubernetes-Elasticsearch","permalink":"http://qhzxc0015.com/tags/kubernetes-Elasticsearch/"}]},{"title":"CoreOS","slug":"05. coreos搭建","date":"2017-08-17T08:32:31.000Z","updated":"2017-09-09T06:52:04.136Z","comments":true,"path":"2017/08/17/05. coreos搭建.html","link":"","permalink":"http://qhzxc0015.com/2017/08/17/05. coreos搭建.html","excerpt":"CoreOS是一个基于Linux 内核的轻量级操作系统，为了计算机集群的基础设施建设而生，专注于自动化，轻松部署，安全，可靠，规模化。作为一个操作系统，CoreOS 提供了在应用容器内部署应用所需要的基础功能环境以及一系列用于服务发现和配置共享的内建工具。","text":"CoreOS是一个基于Linux 内核的轻量级操作系统，为了计算机集群的基础设施建设而生，专注于自动化，轻松部署，安全，可靠，规模化。作为一个操作系统，CoreOS 提供了在应用容器内部署应用所需要的基础功能环境以及一系列用于服务发现和配置共享的内建工具。 参考文献： 使用Vagrant在Windows下部署开发环境 准备工作： 下载安装VirtualBox 下载安装Vagrant git获取Vagrantfile：git clone https://github.com/coreos/coreos-vagrant.git 下载完毕后进入coreos-vagrant文件夹，将config.rb.sample和user-data.sample的sample去掉，修改config.rb中 12$num_instances=1 $update_channel=&apos;alpha&apos; 操作： 启动：vagrant up 状态：vagrant status 进入：vagrant ssh core-01","categories":[],"tags":[{"name":"CoreOS","slug":"CoreOS","permalink":"http://qhzxc0015.com/tags/CoreOS/"},{"name":"Docker","slug":"Docker","permalink":"http://qhzxc0015.com/tags/Docker/"}]},{"title":"Docker Registry","slug":"06. Registry搭建","date":"2017-08-17T08:22:58.000Z","updated":"2017-09-09T06:52:22.375Z","comments":true,"path":"2017/08/17/06. Registry搭建.html","link":"","permalink":"http://qhzxc0015.com/2017/08/17/06. Registry搭建.html","excerpt":"GFW真的强，所以国外镜像真的太难拉下来了,因此采用 docker registry 来存储镜像供其他节点使用","text":"GFW真的强，所以国外镜像真的太难拉下来了,因此采用 docker registry 来存储镜像供其他节点使用 1. Docker版国外镜像真的太难拉下来了,所以采用 docker registry 来存储镜像供其他节点使用,拉取registry镜像sudo docker pull hub.c.163.com/library/registry:2.6.0启动仓库sudo docker run -d -p 5000:5000 -v /docker/registry:/tmp/registry hub.c.163.com/library/registry:2.6.0将各个镜像上传到仓库12sudo docker tag gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64:1.14.2 202.193.74.222/k8s-dns-dnsmasq-nanny-amd64:1.14.2sudo docker push 202.193.74.222:5000/k8s-dns-dnsmasq-nanny-amd64:1.14.2 2. Harbor版参考文献：harbor搭建harbor搭建与问题修改 Harbor也是基于registry镜像进行搭建的,可视化界面比较友好,官网下载分为在线版和离线版,建议用离线版,因为在线版需要自己在国外网站拉取镜像,伟大的墙的威力还是有的,离线版就简单了,直接有版本对应好的镜像. 环境与配置安装环境:docker1.10+,python2.7+,docker-compose1.6.0+下载离线安装包harbor-offline,配置harbor.cfg修改: 123hostname = n2db_password = adminharbor_admin_password = admin #这个是登录密码 启动与访问通过docker-compose.yml修改端口号再通过./prepare来更新配置之后进行./install.sh来安装最后通过docker-compose up -d来启动启动后通过n2:80来访问仓库 登录与上传先进行登录docker login n2:80提示Login Succeeded为安装成功注:这里上传需要先在web端建好项目名,比如上传到仓库名library中: 12sudo docker tag n2:80/library/test:v1sudo docker push n2:80/library/test:v1 3. ErrorsE1: 1234test@Test1:~$ sudo docker push 202.193.74.222:5000/test:latest# ERRORThe push refers to a repository [202.193.74.222:5000/test]Get https://202.193.74.222:5000/v1/_ping: http: server gave HTTP response to HTTPS client 解决方法1:在/etc/docker/目录下，创建daemon.json文件。在文件中写入： 1&#123; &quot;insecure-registries&quot;:[&quot;ip:5000&quot;] &#125; 解决方法2:Centos中vim /etc/sysconfig/docker,在文件中添加: 12ADD_REGISTRY=&apos;--add-registry e2:80&apos;INSECURE_REGISTRY=&apos;--insecure-registry e2:80&apos; 解决方法3:Ubuntu中vim /etc/default/docker,在文件中添加: 1DOCKER_OPTS=&quot;--dns 8.8.8.8 --dns 8.8.4.4 --insecure-registry=n2:80&quot; 重启dockersudo systemctl restart dockerE2: 12345test@Test1:~$ sudo docker push n2:80/library/test:v185782553e37a: Waiting 745f5be9952c: Waiting denied: requested access to the resource is denied 解决方法1:先登录才可以上传,进行登录操作 解决方法2:用hosts名称会异常,建议直接使用ip E3: 1ERROR: for proxy Cannot start service proxy: driver failed programming external connectivity on endpoint nginx (fdeb3e538d5f8d714ea5c79a9f3f127f05f7ba5d519e09c4c30ef81f40b2fe77): Error starting userland proxy: listen tcp 0.0.0.0:80: bind: address already in use 端口占用问题,可以通过修改端口来完成,在harbor/docker-compose.yml中修改,比如此处的80端口修改为8080操作如下: 12345678910111213141516171819202122proxy: image: vmware/nginx:1.11.5-patched container_name: nginx restart: always volumes: - ./common/config/nginx:/etc/nginx:z networks: - harbor ports: - 8080:80 - 444:443 - 4443:4443 depends_on: - mysql - registry - ui - log logging: driver: &quot;syslog&quot; options: syslog-address: &quot;tcp://127.0.0.1:1514&quot; tag: &quot;proxy&quot; 注意这里修改了之后在上面问题E1,E2中的修改也端口 4. Shells批量上传脚本push_images.sh 1234567#!/bin/bashimages=(kube-proxy-amd64:v1.6.6 kube-scheduler-amd64:v1.6.6 kube-controller-manager-amd64:v1.6.6 kube-apiserver-amd64:v1.6.6 etcd-amd64:3.0.17 pause-amd64:3.0 kubernetes-dashboard-amd64:v1.6.1 k8s-dns-sidecar-amd64:1.14.2 k8s-dns-kube-dns-amd64:1.14.2 k8s-dns-dnsmasq-nanny-amd64:1.14.2 etcd:v3.1.5)for imageName in $&#123;images[@]&#125; ; do sudo docker tag gcr.io/google_containers/$imageName e2:5000/$imageName sudo docker push e2:5000/$imageName sudo docker rmi e2:5000/$imageNamedone 批量下载脚本pull_images.sh1234567#!/bin/bash## 标题 ##images=(kube-proxy-amd64:v1.6.6 kube-scheduler-amd64:v1.6.6 kube-controller-manager-amd64:v1.6.6 kube-apiserver-amd64:v1.6.6 etcd-amd64:3.0.17 pause-amd64:3.0 kubernetes-dashboard-amd64:v1.6.1 k8s-dns-sidecar-amd64:1.14.2 k8s-dns-kube-dns-amd64:1.14.2 k8s-dns-dnsmasq-nanny-amd64:1.14.2 etcd:v3.1.5)for imageName in $&#123;images[@]&#125; ; do sudo docker pull e2:5000/$imageName sudo docker tag e2:5000/$imageName gcr.io/google_containers/$imageName sudo docker rmi e2:5000/$imageNamedone","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://qhzxc0015.com/tags/Docker/"},{"name":"Harbor","slug":"Harbor","permalink":"http://qhzxc0015.com/tags/Harbor/"}]},{"title":"Kubernetes DNS服务的安装与配置","slug":"07. kubeDNS","date":"2017-08-15T02:45:04.000Z","updated":"2017-08-29T08:34:00.271Z","comments":true,"path":"2017/08/15/07. kubeDNS.html","link":"","permalink":"http://qhzxc0015.com/2017/08/15/07. kubeDNS.html","excerpt":"Kubernetes的DNS服务是基于SkyDNS实现的，同时又需要和API Server紧密沟通，它的基本工作方式是通过API Server监视服务创建，一旦有新的服务创建就通知SkyDNS创建一条域名解析记录。沟通API Server和SkyDNS的工作都是由Kube2Sky完成的，Kube2sky和Skydns都需要使用ETCD实现共享配置和服务发现。","text":"Kubernetes的DNS服务是基于SkyDNS实现的，同时又需要和API Server紧密沟通，它的基本工作方式是通过API Server监视服务创建，一旦有新的服务创建就通知SkyDNS创建一条域名解析记录。沟通API Server和SkyDNS的工作都是由Kube2Sky完成的，Kube2sky和Skydns都需要使用ETCD实现共享配置和服务发现。 参考文献： Kubernetes DNS服务的安装与配置 Kubernetes技术分析之DNS 部署kubernetes dns服务 Kubernetes DNS服务搭建指南 Kubernetes提供的虚拟DNS服务名为skydns，由四个组件组成： etcd：DNS存储 kube2sky：强Kubernetes Master中的service（服务）注册到etcd。 skyDNS：提供DNS域名解析服务。 healthz：提供对skydns服务的健康检查。 创建两个配置文件skydns-rc.yaml和skydns-svc.yaml： rc.yaml: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596apiVersion: v1kind: ReplicationControllermetadata: name: kube-dns namespace: kube-system labels: k8s-app: kube-dns version: v12 kubernetes.io/cluster-service: &quot;true&quot;spec: replicas: 1 selector: k8s-app: kube-dns version: v12 template: metadata: labels: k8s-app: kube-dns version: v12 kubernetes.io/cluster-service: &quot;true&quot; spec: containers: - name: etcd image: registry.cn-hangzhou.aliyuncs.com/kube_containers/etcd-amd64:3.0.17 resources: limits: cpu: 100m memory: 50Mi requests: cpu: 100m memory: 50Mi command: - /usr/local/bin/etcd - --data-dir - /tmp/data - --listen-client-urls - http://127.0.0.1:2379,http://127.0.0.1:4001 - --advertise-client-urls - http://127.0.0.1:2379,http://127.0.0.1:4001 - --initial-cluster-token - skydns-etcd volumeMounts: - name: etcd-storage mountPath: /tmp/data - name: kube2sky image: gcr.io/google_containers/kube2sky-amd64:1.15 resources: limits: cpu: 100m memory: 50Mi requests: cpu: 100m memory: 50Mi args: - --kube-master-url=http://202.193.74.179:8080 - --domain=cluster.local - name: skydns image: gcr.io/google_containers/skydns-amd64:v1.0 resources: limits: cpu: 100m memory: 50Mi requests: cpu: 100m memory: 50Mi args: - -machines=http://127.0.0.1:4001 - -addr=0.0.0.0:53 - -ns-rotate=false - -domain=cluster.local ports: - containerPort: 53 name: dns protocol: UDP - containerPort: 53 name: dns-tcp protocol: TCP - name: healthz image: gcr.io/google_containers/exechealthz-amd64:1.2 resources: limits: cpu: 10m memory: 20Mi requests: cpu: 10m memory: 20Mi args: - -cmd=nslookup kubernetes.default.svc.cluster.local 127.0.0.1 &gt;/dev/null - -port=8080 ports: - containerPort: 8080 protocol: TCP volumes: - name: etcd-storage emptyDir: &#123;&#125; dnsPolicy: Default svc.yaml: 1234567891011121314151617181920apiVersion: v1kind: Servicemetadata: name: kube-dns namespace: default labels: k8s-app: kube-dns kubernetes.io/cluster-service: &quot;true&quot; kubernetes.io/name: &quot;KubeDNS&quot;spec: selector: k8s-app: kube-dns clusterIP: 10.254.0.10 ports: - name: dns port: 53 protocol: UDP - name: dns-tcp port: 53 protocol: TCP","categories":[],"tags":[{"name":"k8s","slug":"k8s","permalink":"http://qhzxc0015.com/tags/k8s/"},{"name":"kubeDNS","slug":"kubeDNS","permalink":"http://qhzxc0015.com/tags/kubeDNS/"}]},{"title":"Kubernetes 部署","slug":"03. k8s 1.5.2","date":"2017-07-27T07:19:06.000Z","updated":"2017-11-29T13:30:13.135Z","comments":true,"path":"2017/07/27/03. k8s 1.5.2.html","link":"","permalink":"http://qhzxc0015.com/2017/07/27/03. k8s 1.5.2.html","excerpt":"本部署方法通过yum来进行自动安装,k8s版本并不是最新版,此方法简单,高效,操作性强,非常好","text":"本部署方法通过yum来进行自动安装,k8s版本并不是最新版,此方法简单,高效,操作性强,非常好 本部署为1.5.2版本:部署参考;可以根据具体需要进行版本升级:升级参考 1. 前期工作 安装环境 IP NAME 组件 OS 202.193.74.179 Master kube-apiserver,kube-scheduler,kube-controller-manager,etcd Centos 7.2 202.193.75.34 Node kube-proxy kubelet flannel Centos 7.2 202.193.75.11 Node kube-proxy kubelet flannel Centos 7.2 关闭防火墙 12sudo systemctl stop firewalld sudo systemctl disable firewalld 2. 部署环境Master 安装etcd和kubernetessudo yum -y install etcd kubernetes-master 配置文件1.修改/etc/etcd/etcd.conf 1234567891011121314151617181920212223242526272829303132333435363738394041424344# [member]ETCD_NAME=defaultETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot;#ETCD_WAL_DIR=&quot;&quot;#ETCD_SNAPSHOT_COUNT=&quot;10000&quot;#ETCD_HEARTBEAT_INTERVAL=&quot;100&quot;#ETCD_ELECTION_TIMEOUT=&quot;1000&quot;#ETCD_LISTEN_PEER_URLS=&quot;http://localhost:2380&quot;ETCD_LISTEN_CLIENT_URLS=&quot;http://0.0.0.0:2379&quot;#ETCD_MAX_SNAPSHOTS=&quot;5&quot;#ETCD_MAX_WALS=&quot;5&quot;#ETCD_CORS=&quot;&quot;##[cluster]#ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;http://localhost:2380&quot;# if you use different ETCD_NAME (e.g. test), set ETCD_INITIAL_CLUSTER value for this name, i.e. &quot;test=http://...&quot;#ETCD_INITIAL_CLUSTER=&quot;default=http://localhost:2380&quot;#ETCD_INITIAL_CLUSTER_STATE=&quot;new&quot;#ETCD_INITIAL_CLUSTER_TOKEN=&quot;etcd-cluster&quot;ETCD_ADVERTISE_CLIENT_URLS=&quot;http://localhost:2379&quot;#ETCD_DISCOVERY=&quot;&quot;#ETCD_DISCOVERY_SRV=&quot;&quot;#ETCD_DISCOVERY_FALLBACK=&quot;proxy&quot;#ETCD_DISCOVERY_PROXY=&quot;&quot;#ETCD_STRICT_RECONFIG_CHECK=&quot;false&quot;#ETCD_AUTO_COMPACTION_RETENTION=&quot;0&quot;##[proxy]#ETCD_PROXY=&quot;off&quot;#ETCD_PROXY_FAILURE_WAIT=&quot;5000&quot;#ETCD_PROXY_REFRESH_INTERVAL=&quot;30000&quot;#ETCD_PROXY_DIAL_TIMEOUT=&quot;1000&quot;#ETCD_PROXY_WRITE_TIMEOUT=&quot;5000&quot;#ETCD_PROXY_READ_TIMEOUT=&quot;0&quot;##[security]#ETCD_CERT_FILE=&quot;&quot;#ETCD_KEY_FILE=&quot;&quot;#ETCD_CLIENT_CERT_AUTH=&quot;false&quot;#ETCD_TRUSTED_CA_FILE=&quot;&quot;#ETCD_AUTO_TLS=&quot;false&quot;#ETCD_PEER_CERT_FILE=&quot;&quot;#ETCD_PEER_KEY_FILE=&quot;&quot;#ETCD_PEER_CLIENT_CERT_AUTH=&quot;false&quot; 2.修改/etc/kubernetes/apiserver 1234567891011121314151617181920212223242526#### kubernetes system config## The following values are used to configure the kube-apiserver## The address on the local server to listen to.KUBE_API_ADDRESS=&quot;--insecure-bind-address=0.0.0.0&quot;# The port on the local server to listen on.# KUBE_API_PORT=&quot;--port=8080&quot;# Port minions listen on# KUBELET_PORT=&quot;--kubelet-port=10250&quot;# Comma separated list of nodes in the etcd clusterKUBE_ETCD_SERVERS=&quot;--etcd-servers=http://127.0.0.1:2379&quot;# Address range to use for servicesKUBE_SERVICE_ADDRESSES=&quot;--service-cluster-ip-range=10.254.0.0/16&quot;# default admission control policiesKUBE_ADMISSION_CONTROL=&quot;--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ServiceAccount,ResourceQuota&quot;# Add your own!KUBE_API_ARGS=&quot;&quot; 3.修改/etc/kubernetes/controller-manager 1234567#### The following values are used to configure the kubernetes controller-manager# defaults from config and apiserver should be adequate# Add your own!KUBE_CONTROLLER_MANAGER_ARGS=&quot;--node-monitor-grace-period=10s --pod-eviction-timeout=10s&quot; 4.修改/etc/kubernetes/config 12345678910111213141516171819202122#### kubernetes system config## The following values are used to configure various aspects of all# kubernetes services, including## kube-apiserver.service# kube-controller-manager.service# kube-scheduler.service# kubelet.service# kube-proxy.service# logging to stderr means we get it in the systemd journalKUBE_LOGTOSTDERR=&quot;--logtostderr=true&quot;# journal message level, 0 is debugKUBE_LOG_LEVEL=&quot;--v=0&quot;# Should this cluster be allowed to run privileged docker containersKUBE_ALLOW_PRIV=&quot;--allow-privileged=false&quot;# How the controller-manager, scheduler, and proxy find the apiserverKUBE_MASTER=&quot;--master=http://202.193.74.179:8080&quot; 启动服务开机自启sudo systemctl enable etcd kube-apiserver kube-scheduler kube-controller-manager启动服务sudo systemctl start etcd kube-apiserver kube-scheduler kube-controller-manager 配置etcd中的网络node节点的flannel会拉取这里的配置etcdctl mk /coreos.com/network/config &#39;{&quot;Network&quot;:&quot;172.17.0.0/16&quot;}&#39; Node(minions) 安装kubernetes-node和 flannel(会自动安装docker)sudo yum -y install kubernetes-node flannel 配置文件1.修改/etc/kubernetes/config 1234567891011121314151617181920212223#### kubernetes system config## The following values are used to configure various aspects of all# kubernetes services, including## kube-apiserver.service# kube-controller-manager.service# kube-scheduler.service# kubelet.service# kube-proxy.service# logging to stderr means we get it in the systemd journalKUBE_LOGTOSTDERR=&quot;--logtostderr=true&quot;# journal message level, 0 is debugKUBE_LOG_LEVEL=&quot;--v=0&quot;# Should this cluster be allowed to run privileged docker containersKUBE_ALLOW_PRIV=&quot;--allow-privileged=false&quot;# How the controller-manager, scheduler, and proxy find the apiserver#KUBE_MASTER=&quot;--master=http://127.0.0.1:8080&quot;KUBE_MASTER=&quot;--master=http://202.193.74.179:8080&quot; 2.修改/etc/kubernetes/kubelet (注意修改每个node的IP) 1234567891011121314151617181920#### kubernetes kubelet (minion) config# The address for the info server to serve on (set to 0.0.0.0 or &quot;&quot; for all interfaces)KUBELET_ADDRESS=&quot;--address=127.0.0.1&quot;# The port for the info server to serve on# KUBELET_PORT=&quot;--port=10250&quot;# You may leave this blank to use the actual hostnameKUBELET_HOSTNAME=&quot;--hostname-override=202.193.75.11&quot;# location of the api-serverKUBELET_API_SERVER=&quot;--api-servers=http://202.193.74.179:8080&quot;# pod infrastructure containerKUBELET_POD_INFRA_CONTAINER=&quot;--pod-infra-container-image=registry.access.redhat.com/rhel7/pod-infrastructure:latest&quot;# Add your own!KUBELET_ARGS=&quot;--pod-infra-container-image=kubernetes/pause&quot; 3.修改/etc/sysconfig/flanneld 123456789101112# Flanneld configuration options # etcd url location. Point this to the server where etcd runsFLANNEL_ETCD_ENDPOINTS=&quot;http://202.193.74.179:2379&quot;# etcd config key. This is the configuration key that flannel queries# For address range assignment#FLANNEL_ETCD_PREFIX=&quot;/atomic.io/network&quot;FLANNEL_ETCD_PREFIX=&quot;/coreos.com/network&quot;# Any additional options that you want to passFLANNEL_OPTIONS=&quot; -iface=ens33&quot; 其中FLANNEL_OPTIONS=&quot; -iface=eth0&quot;的eth0是网卡名称 启动服务sudo systemctl restart flanneld dockersudo systemctl start kubelet kube-proxysudo systemctl enable flanneld kubelet kube-proxy 3. 验证在master上1234[root@179 centos]# kubectl get nodesNAME STATUS AGE202.193.75.11 Ready 29m202.193.75.34 Ready 6m 4. 附录Error 1: 12[centos@179 message_board]$ kubectl get podsNo resources found. 解决方法:参考链接,认证问题,可以跳过认证方法:12#vim /etc/kubernetes/apiserverKUBE_ADMISSION_CONTROL=&quot;--admission_control=NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota&quot; 5. 添加节点master不变，node修改： Node(minions)中的2.修改/etc/kubernetes/kubelet(注意修改每个node的IP) –IP地址 Node(minions)中的3.修改/etc/sysconfig/flanneld –网卡修改 重启服务sudo systemctl restart flanneld dockersudo systemctl start kubelet kube-proxysudo systemctl enable flanneld kubelet kube-proxy","categories":[],"tags":[{"name":"技术","slug":"技术","permalink":"http://qhzxc0015.com/tags/技术/"},{"name":"k8s","slug":"k8s","permalink":"http://qhzxc0015.com/tags/k8s/"}]},{"title":"Markdown介绍","slug":"02. md介绍","date":"2017-07-20T13:55:06.000Z","updated":"2017-09-09T06:51:11.719Z","comments":true,"path":"2017/07/20/02. md介绍.html","link":"","permalink":"http://qhzxc0015.com/2017/07/20/02. md介绍.html","excerpt":"Markdown 语法简单，记忆负担小，纯文本，流畅书写，无违和感，各种实时渲染效果,所以被刚广泛使用","text":"Markdown 语法简单，记忆负担小，纯文本，流畅书写，无违和感，各种实时渲染效果,所以被刚广泛使用 优点 语法简单，记忆负担小，纯文本，流畅书写，无违和感，各种实时渲染效果。 markdown是为那些需要经常码东西并且进行文字排版的、对码字手速和排版顺畅度有要求的人群设计的，他们希望用键盘把文字内容啪啪啪地打出来后就已经排版好了，最好从头到尾都不要使用鼠标。这些人包括经常需要写文档的码农、博客写手、网站小编、出版业人士等等。 通常情况下，网络上需要进行大量文字输入的地方都可以通过所见即所得的方式排版 再强调一下实时的渲染效果。无论新手老手写 Markdown 的时候最担心的是不知道自己写的对不对，最后渲染效果是不是准确无误。就好象写完代码你一定要自己测试一下才放心，写 Markdown 就是在写代码，实时的渲染效果就是在做测试，这就是为什么网络上有那么多左右两屏带实时渲染的 Markdown 工具的原因（另一个原因是宽屏）1 公式,[^LaTeX]: 支持 LaTeX 编辑显示支持，例如：$\\sum_{i=1}^n a_i=0$， 访问 MathJax $$ x = \\dfrac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} $$ $$\\Gamma(z) = \\int_0^\\infty t^{z-1}e^{-t}dt\\,.$$ $$ \\begin{matrix} 1 &amp; x &amp; x^2 \\ 1 &amp; y &amp; y^2 \\ 1 &amp; z &amp; z^2 \\ \\end{matrix}$$ $$ \\left[ \\begin{array}{cc|c} 1&amp;2&amp;3\\ 4&amp;5&amp;6 \\end{array}\\right] $$ \\begin{align}\\sqrt{37} &amp; = \\sqrt{\\frac{73^2-1}{12^2}} \\ &amp; = \\sqrt{\\frac{73^2}{12^2}\\cdot\\frac{73^2-1}{73^2}} \\ &amp; = \\sqrt{\\frac{73^2}{12^2}}\\sqrt{\\frac{73^2-1}{73^2}} \\ &amp; = \\frac{73}{12}\\sqrt{1 - \\frac{1}{73^2}} \\ &amp; \\approx \\frac{73}{12}\\left(1 - \\frac{1}{2\\cdot73^2}\\right)\\end{align} $ \\newcommand{\\SES}[3]{ 0 \\to #1 \\to #2 \\to #3 \\to 0 } $ 表格| 1 | 2 | 3 | 4 || —- | —: | :–: | —- || 1 | 1 | 1 | 1 | Item Value Computer \\$1600 Phone \\$12 Pipe \\$1 1.这个是脚注 ↩","categories":[],"tags":[{"name":"技术","slug":"技术","permalink":"http://qhzxc0015.com/tags/技术/"},{"name":"Markdown","slug":"Markdown","permalink":"http://qhzxc0015.com/tags/Markdown/"}]},{"title":"hexo基本配置","slug":"01. hexo","date":"2017-07-19T13:55:06.000Z","updated":"2017-08-09T08:56:16.305Z","comments":true,"path":"2017/07/19/01. hexo.html","link":"","permalink":"http://qhzxc0015.com/2017/07/19/01. hexo.html","excerpt":"","text":"这里不错吧,是吧,是吧,来来来,看一下hexo啦~ 常用命令 1234567891011121314hexo clean #清除PUBLIC和编译文件hexo generate #编译网站目录hexo deploy #同步到GIT 或者CODINGnpm install &lt;plugin-name&gt; --save #安装npm update #升级npm uninstall &lt;plugin-name&gt; #卸载hexo new”postName” #新建文章 #存放在主目录的source下的POST目录下hexo new page”pageName” #新建页面hexo generate #生成静态页面至public目录hexo server #开启预览访问端口（默认端口4000，’ctrl + c’关闭server）hexo deploy #将.deploy目录部署到GitHubhexo help # 查看帮助hexo version #查看Hexo的版本 主目录 12345678910├── .deploy #需要部署的文件├── node_modules #Hexo插件├── public #生成的静态网页文件├── scaffolds #模板├── source #博客正文和其他源文件, 404 favicon CNAME 等都应该放在这里| ├── _drafts #草稿| └── _posts #文章├── themes #主题├── _config.yml #全局配置文件└── package.json 主题目录 123456789101112131415161718├── languages #国际化| ├── default.yml #默认| └── zh-CN.yml #中文├── layout #布局| ├── _partial #局部的布局| └── _widget #小挂件的布局├── script #js脚本├── source #源代码文件| ├── css #CSS| | ├── _base #基础CSS| | ├── _partial #局部CSS| | ├── fonts #字体| | ├── images #图片| | └── style.styl #style.css| ├── fancybox #fancybox| └── js #js├── _config.yml #主题配置文件└── README.md #主题介绍 以上目录中常用的有: scaffolds source themes config.yml 根配置文件:_config.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071# Site #站点信息title: lmintlcx #标题subtitle: 做人不卖萌跟咸鱼有什么区别 #副标题description: lmintlcx lm lcx blog #描述author: lmintlcx #作者language: zh-Hans #语言timezone: Asia/Shanghai #时区# URL #链接格式url: http://joryhe.coding.me/ #网址root: / #根目录permalink: post/:title.html #文章的链接格式permalink_defaults:# Directory #目录source_dir: source #源文件public_dir: public #生成的网页文件tag_dir: tags #标签archive_dir: archives #归档category_dir: categories #分类code_dir: downloads/codei18n_dir: :lang #国际化skip_render:# Writing #写作new_post_name: :title.md #新文章标题default_layout: post #默认模板titlecase: false #标题转换成大写external_link: true #新标签页里打开连接filename_case: 0render_drafts: falsepost_asset_folder: falserelative_link: falsefuture: truehighlight: #语法高亮 enable: true line_number: false #显示行号 auto_detect: true tab_replace:# Category &amp; Tag #分类和标签default_category: uncategorized #默认分类category_map:tag_map:# Date / Time format #日期时间格式date_format: YYYY-MM-DDtime_format: HH:mm:ss# Pagination #分页per_page: 20 #每页文章数, 设置成 0 禁用分页pagination_dir: page# Extensions #插件和主题## 插件: http://hexo.io/plugins/## 主题: http://hexo.io/themes/theme: next# Deployment #部署, joryhe是我的用户名, 同时发布GitHub deploy: type: git repo: github: github: git@github.com:joryhe/joryhe.github.io.git,master# Disqus #Disqus评论系统disqus_shortname: plugins: #插件，例如生成 RSS 和站点地图的- hexo-generator-feed- hexo-generator-sitemap 主题配置文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677menu: #菜单 home: / #首页 archives: /archives #归档 about: /about #关于 #commonweal: /404.html #公益404 #tags: /tags #标签 #categories: /categories #分类## 经典介绍配置# 小图标favicon: /favicon.ico# 默认关键词keywords: # 留空使用默认的, false 禁用, 也可以写指定的地址rss:# Icon fonts# default | linecons | fifty-shades | feathericon_font: default# 代码高亮主题 https://github.com/chriskempson/tomorrow-theme# normal | night | night eighties | night blue | night brighthighlight_theme: normal# MathJax Support #数学公式mathjax: true# Schemes #启用主题中的主题Mistscheme: Mist# 侧边栏# - post 只在文章页面显示# - always 所有页面显示# - hide 隐藏sidebar: always# 自动滚动到&quot;阅读更多&quot;标记的下面scroll_to_more: true# 自动给目录添加序号toc_list_number: true# 自动截取摘要auto_excerpt: enable: false length: 150# Lato 字体use_font_lato: true# Make duoshuo show UA# user_id must NOT be null when admin_enable is true!# you can visit http://dev.duoshuo.com get duoshuo user id.duoshuo_info: ua_enable: true admin_enable: false user_id: 0 #admin_nickname: ROOT## DO NOT EDIT THE FOLLOWING SETTINGS## UNLESS YOU KNOW WHAT YOU ARE DOING# 动画use_motion: true# Fancybox 看图插件fancybox: true# Static filesvendors: vendorscss: cssjs: jsimages: images# Theme versionversion: 0.4.5.1","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://qhzxc0015.com/tags/hexo/"}]}]}