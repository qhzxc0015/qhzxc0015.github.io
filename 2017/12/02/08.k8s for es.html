<!DOCTYPE html>
<html lang="zh-CN">

<!-- Head tag -->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <!--Description-->
  
  <meta name="description" content="程序猿 | 熬夜猫 | 次元狗">
  

  <!--Author-->
  
  <meta name="author" content="zxc">
  

  <!--Open Graph Title-->
  
      <meta property="og:title" content="kubernetes for Elasticsearch"/>
  
  <!--Open Graph Description-->
  
      <meta property="og:description" content="程序猿 | 熬夜猫 | 次元狗" />
  
  <!--Open Graph Site Name-->
  <meta property="og:site_name" content="thk_days"/>
  <!--Type page-->
  
      <meta property="og:type" content="article" />
  
  <!--Page Cover-->
  

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <!-- 百度统计 -->
    <script>
	var _hmt = _hmt || [];
	(function() {
  	var hm = document.createElement("script");
  	hm.src = "https://hm.baidu.com/hm.js?c0451e16533956173997b85f7a8de666";
  	var s = document.getElementsByTagName("script")[0]; 
  	s.parentNode.insertBefore(hm, s);
	})();
    </script>
  <!-- Title -->
  
  <title>kubernetes for Elasticsearch - thk_days</title>


  <link rel="shortcut icon" href="/favicon.ico">
    <!--font-awesome-->
  <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css">
  <!-- Custom CSS/Sass -->
  <link rel="stylesheet" href="/css/style.css">

</head>


<body>

  <!-- Nav -->
  <header class="site-header">
  <div class="header-inside">
    
    <div class="logo">
      <a href="/" rel="home">
        
        <img src="http://ou9i51fe5.bkt.clouddn.com/myface.gif" alt="thk_days" height="60">
        
      </a>
    </div>
    <a class="header-name" href="/">
            <span>thk_days</span>
            的部落宅
        </a>
    <!-- navbar -->
    <nav class="navbar">
      <!--  nav links -->
      <div class="collapse">
        <ul class="navbar-nav">
          
          
            <li>
              <a href="/.">
                
                  <i class="fa fa-home "></i>
                
                首页
              </a>
            </li>
          
            <li>
              <a href="/archives">
                
                  <i class="fa fa-archive "></i>
                
                归档
              </a>
            </li>
          
            <li>
              <a href="/about">
                
                  <i class="fa fa-user "></i>
                
                关于
              </a>
            </li>
          
            <li>
              <a href="/photos">
                
                  <i class="fa fa-photo "></i>
                
                相册
              </a>
            </li>
          
            <li>
              <a href="/atom.xml">
                
                  <i class="fa fa-send "></i>
                
                RSS
              </a>
            </li>
          
        </ul>
      </div>
      <!-- /.navbar-collapse -->
    </nav>
    <div class="button-wrap">
      <button class="menu-toggle">Primary Menu</button>
    </div>
  </div>
</header>


  <!-- Main Content -->
  <div class="content-area">
  <div class="post">
    <!-- Post Content -->
    <div class="container">
      <article>
        <!-- Title date & tags -->
        <div class="post-header">
          <h1 class="entry-title">
            kubernetes for Elasticsearch
            
          </h1>
         
        </div>
         <p class="a-posted-on">
          2017-12-02
          </p>
        <!-- Post Main Content -->
        <div class="entry-content">
          <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><blockquote>
</blockquote>
<p><img src="http://ou9i51fe5.bkt.clouddn.com/k8s.png" alt=""><br><a id="more"></a></p>
<hr>
<p>参考文献：</p>
<ol>
<li><a href="http://blog.csdn.net/xts_huangxin/article/details/52290703" target="_blank" rel="external">使用k8s编排ElasticSearch集群</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/tree/release-1.3/examples/elasticsearch/" target="_blank" rel="external">Elasticsearch for Kubernetes</a></li>
<li><a href="http://blog.csdn.net/dream_broken/article/details/52954069" target="_blank" rel="external">CentOS7.2使用yum安装kubernetes</a></li>
<li><a href="https://yq.aliyun.com/articles/11035" target="_blank" rel="external">ETCD系列</a></li>
</ol>
<h2 id="1-Kubernetes搭建"><a href="#1-Kubernetes搭建" class="headerlink" title="1. Kubernetes搭建"></a>1. Kubernetes搭建</h2><h3 id="1-1-准备工作"><a href="#1-1-准备工作" class="headerlink" title="1.1 准备工作"></a>1.1 准备工作</h3><h4 id="1-1-1-关闭防火墙"><a href="#1-1-1-关闭防火墙" class="headerlink" title="1.1.1 关闭防火墙"></a>1.1.1 关闭防火墙</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">systemctl stop firewalld  </div><div class="line">systemctl disable firewalld</div></pre></td></tr></table></figure>
<h4 id="1-1-2-安装NTP"><a href="#1-1-2-安装NTP" class="headerlink" title="1.1.2 安装NTP"></a>1.1.2 安装NTP</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">yum -y install ntp  </div><div class="line">systemctl start ntpd  </div><div class="line">systemctl enable ntpd</div></pre></td></tr></table></figure>
<h4 id="1-1-3-禁用selinux"><a href="#1-1-3-禁用selinux" class="headerlink" title="1.1.3 禁用selinux"></a>1.1.3 禁用selinux</h4><p><code>vim /etc/selinux/config</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">#SELINUX=enforcing  </div><div class="line">SELINUX=disabled</div></pre></td></tr></table></figure></p>
<hr>
<h3 id="2-2-搭建kubernetes"><a href="#2-2-搭建kubernetes" class="headerlink" title="2.2 搭建kubernetes"></a>2.2 搭建kubernetes</h3><h4 id="2-1-1-环境配置以及角色"><a href="#2-1-1-环境配置以及角色" class="headerlink" title="2.1.1 环境配置以及角色"></a>2.1.1 环境配置以及角色</h4><table>
<thead>
<tr>
<th>IP</th>
<th>Hosts</th>
<th>Role</th>
</tr>
</thead>
<tbody>
<tr>
<td>202.193.74.179</td>
<td>master,etcd</td>
<td>etcd kube-apiserver kube-scheduler kube-controller-manage flannel</td>
</tr>
<tr>
<td>202.193.75.80</td>
<td>node1</td>
<td>docker kube-proxy kubelet flannel</td>
</tr>
<tr>
<td>202.193.75.34</td>
<td>node2</td>
<td>docker kube-proxy kubelet flannel</td>
</tr>
</tbody>
</table>
<h4 id="2-1-2-安装etcd"><a href="#2-1-2-安装etcd" class="headerlink" title="2.1.2 安装etcd"></a>2.1.2 安装etcd</h4><blockquote>
<p>etcd用于服务发现和服务注册，解决客户端如何知道多节点上服务的IP地址和端口问题。Etcd组件作为一个高可用强一致性的服务发现存储仓库,etcd服务需要提供kubernetes集群的所有节点，因此需要监听于可用于外部通信的地址。</p>
</blockquote>
<p>安装步骤方法：<br><code>yum install -y etcd</code><br>检测安装：<code>rpm -ql etcd</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">[centos@179 es]$ rpm -ql etcd</div><div class="line">/etc/etcd</div><div class="line">/etc/etcd/etcd.conf</div><div class="line">/usr/bin/etcd</div><div class="line">/usr/bin/etcdctl</div><div class="line">/usr/lib/systemd/system/etcd.service</div><div class="line">/usr/share/doc/etcd-3.1.9</div><div class="line">/usr/share/doc/etcd-3.1.9/CONTRIBUTING.md</div><div class="line">/usr/share/doc/etcd-3.1.9/README.md</div><div class="line">/usr/share/doc/etcd-3.1.9/ROADMAP.md</div><div class="line">/usr/share/doc/etcd-3.1.9/glide.lock</div><div class="line">/usr/share/licenses/etcd-3.1.9</div><div class="line">/usr/share/licenses/etcd-3.1.9/LICENSE</div><div class="line">/var/lib/etcd</div></pre></td></tr></table></figure></p>
<p>对其中/etc/etcd/etcd.conf文件进行配置<code>sudo vim /etc/etcd/etcd.conf</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line"># [member]</div><div class="line">ETCD_NAME=default</div><div class="line">ETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot;</div><div class="line">#ETCD_WAL_DIR=&quot;&quot;</div><div class="line">#ETCD_SNAPSHOT_COUNT=&quot;10000&quot;</div><div class="line">#ETCD_HEARTBEAT_INTERVAL=&quot;100&quot;</div><div class="line">#ETCD_ELECTION_TIMEOUT=&quot;1000&quot;</div><div class="line">ETCD_LISTEN_PEER_URLS=&quot;http://master:2380&quot;</div><div class="line">ETCD_LISTEN_CLIENT_URLS=&quot;http://master:2379&quot;</div><div class="line">#ETCD_MAX_SNAPSHOTS=&quot;5&quot;</div><div class="line">#ETCD_MAX_WALS=&quot;5&quot;</div><div class="line">#ETCD_CORS=&quot;&quot;</div><div class="line">#</div><div class="line">#[cluster]</div><div class="line">ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;http://master:2380&quot;</div><div class="line"># if you use different ETCD_NAME (e.g. test), set ETCD_INITIAL_CLUSTER value for this name, i.e. &quot;test=http://...&quot;</div><div class="line">ETCD_INITIAL_CLUSTER=&quot;default=http://etcd:2380&quot;</div><div class="line">#ETCD_INITIAL_CLUSTER_STATE=&quot;new&quot;</div><div class="line">#ETCD_INITIAL_CLUSTER_TOKEN=&quot;etcd-cluster&quot;</div><div class="line">ETCD_ADVERTISE_CLIENT_URLS=&quot;http://master:2379&quot;</div><div class="line">#ETCD_DISCOVERY=&quot;&quot;</div><div class="line">#ETCD_DISCOVERY_SRV=&quot;&quot;</div><div class="line">#ETCD_DISCOVERY_FALLBACK=&quot;proxy&quot;</div><div class="line">#ETCD_DISCOVERY_PROXY=&quot;&quot;</div><div class="line">#ETCD_STRICT_RECONFIG_CHECK=&quot;false&quot;</div><div class="line">#ETCD_AUTO_COMPACTION_RETENTION=&quot;0&quot;</div><div class="line">#</div><div class="line">#[proxy]</div><div class="line">#ETCD_PROXY=&quot;off&quot;</div><div class="line">#ETCD_PROXY_FAILURE_WAIT=&quot;5000&quot;</div><div class="line">#ETCD_PROXY_REFRESH_INTERVAL=&quot;30000&quot;</div><div class="line">#ETCD_PROXY_DIAL_TIMEOUT=&quot;1000&quot;</div><div class="line">#ETCD_PROXY_WRITE_TIMEOUT=&quot;5000&quot;</div><div class="line">#ETCD_PROXY_READ_TIMEOUT=&quot;0&quot;</div><div class="line">#</div><div class="line">#[security]</div><div class="line">#ETCD_CERT_FILE=&quot;&quot;</div><div class="line">#ETCD_KEY_FILE=&quot;&quot;</div><div class="line">#ETCD_CLIENT_CERT_AUTH=&quot;false&quot;</div><div class="line">#ETCD_TRUSTED_CA_FILE=&quot;&quot;</div><div class="line">#ETCD_AUTO_TLS=&quot;false&quot;</div><div class="line">#ETCD_PEER_CERT_FILE=&quot;&quot;</div><div class="line">#ETCD_PEER_KEY_FILE=&quot;&quot;</div><div class="line">#ETCD_PEER_CLIENT_CERT_AUTH=&quot;false&quot;</div></pre></td></tr></table></figure></p>
<p>配置完毕，重启服务<br><code>sudo systemctl restart etcd</code><br>查看集群健康程度：<code>etcdctl -C http://master:2379 cluster-health</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">member 8e9e05c52164694d is healthy: got healthy result from http://master:2379</div><div class="line">cluster is healthy</div></pre></td></tr></table></figure></p>
<p>创建目录：<code>etcdctl -C http://master:2379 mkdir /testdir</code><br>查看目录：<code>etcdctl -C http://master:2379 ls</code><br>给newkey一个helloetcd值：<code>etcdctl -C http://master:2379 mk /testdir/newkey helloetcd</code></p>
<h4 id="2-1-3-安装kubernetes"><a href="#2-1-3-安装kubernetes" class="headerlink" title="2.1.3 安装kubernetes"></a>2.1.3 安装kubernetes</h4><ul>
<li>master节点<br>查看所有kubernetes安装包:<code>yum list all kubernetes*</code><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">已加载插件：fastestmirror, langpacks</div><div class="line">Determining fastest mirrors</div><div class="line"> * base: centos.ustc.edu.cn</div><div class="line"> * extras: mirrors.sohu.com</div><div class="line"> * updates: mirrors.aliyun.com</div><div class="line">kubernetes-client.x86_64      1.5.2-0.7.git269f928.el7      @extras</div><div class="line">kubernetes-node.x86_64        1.5.2-0.7.git269f928.el7      @extras</div><div class="line">kubernetes.x86_64               1.5.2-0.7.git269f928.el7      extras </div><div class="line">kubernetes-master.x86_64      1.5.2-0.7.git269f928.el7      extras </div><div class="line">kubernetes-unit-test.x86_64   1.5.2-0.7.git269f928.el7      extras</div></pre></td></tr></table></figure>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">已加载插件：fastestmirror, langpacks</div><div class="line">Loading mirror speeds from cached hostfile</div><div class="line"> * base: mirrors.nwsuaf.edu.cn</div><div class="line"> * extras: ftp.sjtu.edu.cn</div><div class="line"> * updates: mirrors.aliyun.com</div><div class="line">kubernetes-client.x86_64             1.5.2-0.7.git269f928.el7    </div><div class="line">kubernetes-master.x86_64             1.5.2-0.7.git269f928.el7    </div><div class="line">kubernetes.x86_64                    1.5.2-0.7.git269f928.el7    </div><div class="line">kubernetes-node.x86_64               1.5.2-0.7.git269f928.el7    </div><div class="line">kubernetes-unit-test.x86_64          1.5.2-0.7.git269f928.el7</div></pre></td></tr></table></figure>
<p>安装master：<code>sudo yum install -y kubernetes-master</code><br>安装kubernetes-master的时候也安装了kubernetes-client。<br>查看安全：<code>rpm -ql kubernetes-master</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">/etc/kubernetes</div><div class="line">/etc/kubernetes/apiserver</div><div class="line">/etc/kubernetes/config</div><div class="line">/etc/kubernetes/controller-manager</div><div class="line">/etc/kubernetes/scheduler</div><div class="line">/run/kubernetes</div><div class="line">/usr/bin/hyperkube</div><div class="line">/usr/bin/kube-apiserver</div><div class="line">/usr/bin/kube-controller-manager</div><div class="line">/usr/bin/kube-scheduler</div><div class="line">/usr/lib/systemd/system/kube-apiserver.service</div><div class="line">/usr/lib/systemd/system/kube-controller-manager.service</div><div class="line">/usr/lib/systemd/system/kube-scheduler.service</div><div class="line">/usr/lib/tmpfiles.d/kubernetes.conf</div><div class="line">/usr/share/doc/kubernetes-master-1.5.2</div><div class="line">/usr/share/doc/kubernetes-master-1.5.2/CHANGELOG.md</div><div class="line">/usr/share/doc/kubernetes-master-1.5.2/CONTRIBUTING.md</div><div class="line">/usr/share/doc/kubernetes-master-1.5.2/README.md</div><div class="line">/usr/share/doc/kubernetes-master-1.5.2/code-of-conduct.md</div><div class="line">/usr/share/licenses/kubernetes-master-1.5.2</div><div class="line">/usr/share/licenses/kubernetes-master-1.5.2/LICENSE</div><div class="line">/usr/share/man/man1/kube-apiserver.1.gz</div><div class="line">/usr/share/man/man1/kube-controller-manager.1.gz</div><div class="line">/usr/share/man/man1/kube-scheduler.1.gz</div></pre></td></tr></table></figure></p>
<p>查看安装：<code>rpm -ql kubernetes-client</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">/usr/bin/hyperkube</div><div class="line">/usr/bin/kubectl</div><div class="line">/usr/share/bash-completion/completions/kubectl</div><div class="line">/usr/share/doc/kubernetes-client-1.5.2</div><div class="line">/usr/share/doc/kubernetes-client-1.5.2/CHANGELOG.md</div><div class="line">/usr/share/doc/kubernetes-client-1.5.2/CONTRIBUTING.md</div><div class="line">/usr/share/doc/kubernetes-client-1.5.2/README.md</div><div class="line">/usr/share/doc/kubernetes-client-1.5.2/code-of-conduct.md</div><div class="line">/usr/share/licenses/kubernetes-client-1.5.2</div><div class="line">/usr/share/licenses/kubernetes-client-1.5.2/LICENSE</div><div class="line">.....</div></pre></td></tr></table></figure></p>
<p>对其中的apiserver进行修改<code>sudo vim apiserver</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">###</div><div class="line"># kubernetes system config</div><div class="line">#</div><div class="line"># The following values are used to configure the kube-apiserver</div><div class="line">#</div><div class="line"># The address on the local server to listen to.</div><div class="line">KUBE_API_ADDRESS=&quot;--insecure-bind-address=0.0.0.0&quot;</div><div class="line"># The port on the local server to listen on.</div><div class="line"># KUBE_API_PORT=&quot;--port=8080&quot;</div><div class="line"># Port minions listen on</div><div class="line"># KUBELET_PORT=&quot;--kubelet_port=10250&quot;</div><div class="line"># Comma separated list of nodes in the etcd cluster</div><div class="line">KUBE_ETCD_SERVERS=&quot;--etcd-servers=http://etcd:2379&quot;</div><div class="line"># Address range to use for services</div><div class="line">KUBE_SERVICE_ADDRESSES=&quot;--service-cluster-ip-range=10.254.0.0/16&quot;</div><div class="line"># default admission control policies</div><div class="line"># KUBE_ADMISSION_CONTROL=&quot;--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ServiceAccount,ResourceQuota&quot;</div><div class="line">KUBE_ADMISSION_CONTROL=&quot;--admission_control=NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota&quot;</div><div class="line"># Add your own!</div><div class="line">KUBE_API_ARGS=&quot;&quot;</div></pre></td></tr></table></figure></p>
<blockquote>
<p>注意：KUBE_ADMISSION_CONTROL选项里删除ServiceAccount选项。不用帐号密码认证，麻烦。<br>对config进行修改<code>sudo vim config</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">###</div><div class="line"># kubernetes system config</div><div class="line">#</div><div class="line"># The following values are used to configure various aspects of all</div><div class="line"># kubernetes services, including</div><div class="line">#</div><div class="line">#   kube-apiserver.service</div><div class="line">#   kube-controller-manager.service</div><div class="line">#   kube-scheduler.service</div><div class="line">#   kubelet.service</div><div class="line">#   kube-proxy.service</div><div class="line"># logging to stderr means we get it in the systemd journal</div><div class="line">KUBE_LOGTOSTDERR=&quot;--logtostderr=true&quot;</div><div class="line"># journal message level, 0 is debug</div><div class="line">KUBE_LOG_LEVEL=&quot;--v=0&quot;</div><div class="line"># Should this cluster be allowed to run privileged docker containers</div><div class="line">KUBE_ALLOW_PRIV=&quot;--allow-privileged=false&quot;</div><div class="line"># How the controller-manager, scheduler, and proxy find the apiserver</div><div class="line">KUBE_MASTER=&quot;--master=http://master:8080&quot;</div></pre></td></tr></table></figure></p>
</blockquote>
<p>配置完成，启动服务kubernetes-master<br><code>systemctl start kube-apiserver.service kube-controller-manager.service kube-scheduler.service</code></p>
<ul>
<li>node节点<br>1.docker安装：<code>yum install -y docker</code><br>2.kubernetes-node安装：<code>yum install -y kubernetes-node</code><br>查看安装<code>rpm -ql kubernetes-node</code><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">/etc/kubernetes</div><div class="line">/etc/kubernetes/config</div><div class="line">/etc/kubernetes/kubelet</div><div class="line">/etc/kubernetes/proxy</div><div class="line">/etc/systemd/system.conf.d/kubernetes-accounting.conf</div><div class="line">/run/kubernetes</div><div class="line">/usr/bin/hyperkube</div><div class="line">/usr/bin/kube-proxy</div><div class="line">/usr/bin/kubelet</div><div class="line">/usr/lib/systemd/system/kube-proxy.service</div><div class="line">/usr/lib/systemd/system/kubelet.service</div><div class="line">/usr/lib/tmpfiles.d/kubernetes.conf</div><div class="line">/usr/share/doc/kubernetes-node-1.5.2</div><div class="line">/usr/share/doc/kubernetes-node-1.5.2/CHANGELOG.md</div><div class="line">/usr/share/doc/kubernetes-node-1.5.2/CONTRIBUTING.md</div><div class="line">/usr/share/doc/kubernetes-node-1.5.2/README.md</div><div class="line">/usr/share/doc/kubernetes-node-1.5.2/code-of-conduct.md</div><div class="line">/usr/share/licenses/kubernetes-node-1.5.2</div><div class="line">/usr/share/licenses/kubernetes-node-1.5.2/LICENSE</div><div class="line">/usr/share/man/man1/kube-proxy.1.gz</div><div class="line">/usr/share/man/man1/kubelet.1.gz</div><div class="line">/var/lib/kubelet</div></pre></td></tr></table></figure>
</li>
</ul>
<p>修改kubelet<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">###</div><div class="line"># kubernetes kubelet (minion) config</div><div class="line"></div><div class="line"># The address for the info server to serve on (set to 0.0.0.0 or &quot;&quot; for all interfaces)</div><div class="line">KUBELET_ADDRESS=&quot;--address=0.0.0.0&quot;</div><div class="line"></div><div class="line"># The port for the info server to serve on</div><div class="line"># KUBELET_PORT=&quot;--port=10250&quot;</div><div class="line"></div><div class="line"># You may leave this blank to use the actual hostname</div><div class="line">KUBELET_HOSTNAME=&quot;--hostname-override=node1&quot;</div><div class="line"></div><div class="line"># location of the api-server</div><div class="line">KUBELET_API_SERVER=&quot;--api-servers=http://master:8080&quot;</div><div class="line"></div><div class="line"># pod infrastructure container</div><div class="line">KUBELET_POD_INFRA_CONTAINER=&quot;--pod-infra-container-image=registry.access.redhat.com/rhel7/pod-infrastructure:latest&quot;</div><div class="line"></div><div class="line"># Add your own!</div><div class="line">KUBELET_ARGS=&quot;--pod-infra-container-image=kubernetes/pause&quot;</div></pre></td></tr></table></figure></p>
<p>修改config<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">###</div><div class="line"># kubernetes system config</div><div class="line">#</div><div class="line"># The following values are used to configure various aspects of all</div><div class="line"># kubernetes services, including</div><div class="line">#</div><div class="line">#   kube-apiserver.service</div><div class="line">#   kube-controller-manager.service</div><div class="line">#   kube-scheduler.service</div><div class="line">#   kubelet.service</div><div class="line">#   kube-proxy.service</div><div class="line"># logging to stderr means we get it in the systemd journal</div><div class="line">KUBE_LOGTOSTDERR=&quot;--logtostderr=true&quot;</div><div class="line"></div><div class="line"># journal message level, 0 is debug</div><div class="line">KUBE_LOG_LEVEL=&quot;--v=0&quot;</div><div class="line"></div><div class="line"># Should this cluster be allowed to run privileged docker containers</div><div class="line">KUBE_ALLOW_PRIV=&quot;--allow-privileged=false&quot;</div><div class="line"></div><div class="line"># How the controller-manager, scheduler, and proxy find the apiserver</div><div class="line">#KUBE_MASTER=&quot;--master=http://127.0.0.1:8080&quot;</div><div class="line">KUBE_MASTER=&quot;--master=http://master:8080&quot;</div></pre></td></tr></table></figure></p>
<p>启动服务：<code>systemctl start kubelet.service kube-proxy.service</code><br>添加节点，config不变，只需修改kubelet<br>启动服务后可以查看端口<code>netstat -tln</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">Proto Recv-Q Send-Q Local Address           Foreign Address         State      </div><div class="line">tcp        0      0 127.0.0.1:10248         0.0.0.0:*               LISTEN     </div><div class="line">tcp        0      0 127.0.0.1:10249         0.0.0.0:*               LISTEN     </div><div class="line">tcp        0      0 192.168.122.1:53        0.0.0.0:*               LISTEN     </div><div class="line">tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN     </div><div class="line">tcp        0      0 127.0.0.1:631           0.0.0.0:*               LISTEN     </div><div class="line">tcp        0      0 127.0.0.1:25            0.0.0.0:*               LISTEN     </div><div class="line">tcp6       0      0 :::10250                :::*                    LISTEN     </div><div class="line">tcp6       0      0 :::10255                :::*                    LISTEN     </div><div class="line">tcp6       0      0 :::22                   :::*                    LISTEN     </div><div class="line">tcp6       0      0 ::1:631                 :::*                    LISTEN     </div><div class="line">tcp6       0      0 :::31480                :::*                    LISTEN     </div><div class="line">tcp6       0      0 ::1:25                  :::*                    LISTEN     </div><div class="line">tcp6       0      0 :::31451                :::*                    LISTEN     </div><div class="line">tcp6       0      0 :::4194                 :::*                    LISTEN     </div><div class="line">tcp6       0      0 :::31685                :::*                    LISTEN</div></pre></td></tr></table></figure></p>
<p>其中4194位cAdvisor服务</p>
<h4 id="2-1-3-安装flannel"><a href="#2-1-3-安装flannel" class="headerlink" title="2.1.3 安装flannel"></a>2.1.3 安装flannel</h4><blockquote>
<p>k8s的网络管理用flannel网络。所以三个节点(master,node1,node2)都要装。</p>
</blockquote>
<p><code>yum install -y flannel</code><br><code>rpm -ql flannel</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">/run/flannel</div><div class="line">/usr/bin/flanneld</div><div class="line">/usr/bin/flanneld-start</div><div class="line">/usr/lib/systemd/system/docker.service.d/flannel.conf</div><div class="line">/usr/lib/systemd/system/flanneld.service</div><div class="line">/usr/lib/tmpfiles.d/flannel.conf</div><div class="line">/usr/libexec/flannel</div><div class="line">/usr/libexec/flannel/mk-docker-opts.sh</div><div class="line">/usr/share/doc/flannel-0.7.1</div><div class="line">/usr/share/doc/flannel-0.7.1/CONTRIBUTING.md</div><div class="line">/usr/share/doc/flannel-0.7.1/DCO</div><div class="line">/usr/share/doc/flannel-0.7.1/LICENSE</div><div class="line">/usr/share/doc/flannel-0.7.1/MAINTAINERS</div><div class="line">/usr/share/doc/flannel-0.7.1/NOTICE</div><div class="line">/usr/share/doc/flannel-0.7.1/README.md</div></pre></td></tr></table></figure></p>
<p><code>sudo vim /etc/sysconfig/flanneld</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"># Flanneld configuration options  </div><div class="line"></div><div class="line"># etcd url location.  Point this to the server where etcd runs</div><div class="line">FLANNEL_ETCD_ENDPOINTS=&quot;http://etcd:2379&quot;</div><div class="line"></div><div class="line"># etcd config key.  This is the configuration key that flannel queries</div><div class="line"># For address range assignment</div><div class="line">FLANNEL_ETCD_PREFIX=&quot;/coreos.com/network&quot;</div><div class="line"></div><div class="line"># Any additional options that you want to pass</div><div class="line">FANNEL_OPTIONS=&quot; -iface=ens33&quot;</div></pre></td></tr></table></figure></p>
<p>master需要etcd讲键值存入：<code>etcdctl -C http://etcd1:2379 mk /ilinux.io/network/config &#39;{&quot;Network&quot;:&quot;10.7.0.0/16&quot;}&#39;</code><br>启动flannel服务：<code>systemcl start flanneld.service</code><br>通过ifconfig进行查看<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">docker0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1472</div><div class="line">        inet 10.7.8.1  netmask 255.255.255.0  broadcast 0.0.0.0</div><div class="line">        inet6 fe80::42:97ff:fe39:3861  prefixlen 64  scopeid 0x20&lt;link&gt;</div><div class="line">        ether 02:42:97:39:38:61  txqueuelen 0  (Ethernet)</div><div class="line">        RX packets 53  bytes 3474 (3.3 KiB)</div><div class="line">        RX errors 0  dropped 0  overruns 0  frame 0</div><div class="line">        TX packets 46  bytes 5360 (5.2 KiB)</div><div class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</div><div class="line"></div><div class="line">ens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</div><div class="line">        inet 202.193.75.34  netmask 255.255.254.0  broadcast 202.193.75.255</div><div class="line">        inet6 fe80::20c:29ff:fe65:c10f  prefixlen 64  scopeid 0x20&lt;link&gt;</div><div class="line">        ether 00:0c:29:65:c1:0f  txqueuelen 1000  (Ethernet)</div><div class="line">        RX packets 34213307  bytes 4678823447 (4.3 GiB)</div><div class="line">        RX errors 0  dropped 2  overruns 0  frame 0</div><div class="line">        TX packets 1419255  bytes 781178180 (744.9 MiB)</div><div class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</div><div class="line"></div><div class="line">flannel0: flags=4305&lt;UP,POINTOPOINT,RUNNING,NOARP,MULTICAST&gt;  mtu 1472</div><div class="line">        inet 10.7.8.0  netmask 255.255.0.0  destination 10.7.8.0</div><div class="line">        unspec 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00  txqueuelen 500  (UNSPEC)</div><div class="line">        RX packets 0  bytes 0 (0.0 B)</div><div class="line">        RX errors 0  dropped 0  overruns 0  frame 0</div><div class="line">        TX packets 0  bytes 0 (0.0 B)</div><div class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</div></pre></td></tr></table></figure></p>
<hr>
<h2 id="3-1-搭建es"><a href="#3-1-搭建es" class="headerlink" title="3.1 搭建es"></a>3.1 搭建es</h2><h3 id="3-1-1-拉取镜像"><a href="#3-1-1-拉取镜像" class="headerlink" title="3.1.1 拉取镜像"></a>3.1.1 拉取镜像</h3><p><code>sudo docker docker.io/kayrus/docker-elasticsearch-kubernetes:1.7.1</code></p>
<h3 id="部署文件"><a href="#部署文件" class="headerlink" title="部署文件"></a>部署文件</h3><p>es-rc.yaml<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line">apiVersion: v1</div><div class="line">kind: ReplicationController</div><div class="line">metadata:</div><div class="line">  name: es</div><div class="line">  labels:</div><div class="line">    component: elasticsearch</div><div class="line">spec:</div><div class="line">  replicas: 1</div><div class="line">  template:</div><div class="line">    metadata:</div><div class="line">      labels:</div><div class="line">        component: elasticsearch</div><div class="line">    spec:</div><div class="line">      serviceAccount: elasticsearch</div><div class="line">      containers:</div><div class="line">      - name: es</div><div class="line">        securityContext:</div><div class="line">          capabilities:</div><div class="line">            add:</div><div class="line">              - IPC_LOCK</div><div class="line">        image: docker.io/kayrus/docker-elasticsearch-kubernetes:1.7.1</div><div class="line">        env:</div><div class="line">        - name: KUBERNETES_CA_CERTIFICATE_FILE</div><div class="line">          value: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</div><div class="line">        - name: NAMESPACE</div><div class="line">          valueFrom:</div><div class="line">            fieldRef:</div><div class="line">              fieldPath: metadata.namespace</div><div class="line">        - name: &quot;CLUSTER_NAME&quot;</div><div class="line">          value: &quot;myesdb&quot;</div><div class="line">        - name: &quot;DISCOVERY_SERVICE&quot;</div><div class="line">          value: &quot;elasticsearch&quot;</div><div class="line">        - name: NODE_MASTER</div><div class="line">          value: &quot;true&quot;</div><div class="line">        - name: NODE_DATA</div><div class="line">          value: &quot;true&quot;</div><div class="line">        - name: HTTP_ENABLE</div><div class="line">          value: &quot;true&quot;</div><div class="line">        ports:</div><div class="line">        - containerPort: 9200</div><div class="line">          name: http</div><div class="line">          protocol: TCP</div><div class="line">        - containerPort: 9300</div><div class="line">          name: transport</div><div class="line">          protocol: TCP</div><div class="line">        volumeMounts:</div><div class="line">        - mountPath: /data</div><div class="line">          name: storage</div><div class="line">      volumes:</div><div class="line">      - name: storage</div><div class="line">        emptyDir: &#123;&#125;</div></pre></td></tr></table></figure></p>
<p>es-svc.yaml<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">apiVersion: v1</div><div class="line">kind: Service</div><div class="line">metadata:</div><div class="line">  name: elasticsearch</div><div class="line">  labels:</div><div class="line">    component: elasticsearch</div><div class="line">spec:</div><div class="line">  type: LoadBalancer</div><div class="line">  selector:</div><div class="line">    component: elasticsearch</div><div class="line">  ports:</div><div class="line">  - name: http</div><div class="line">    port: 9200</div><div class="line">    protocol: TCP</div><div class="line">  - name: transport</div><div class="line">    port: 9300</div><div class="line">    protocol: TCP</div></pre></td></tr></table></figure></p>
<p>service-account.yaml<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">apiVersion: v1</div><div class="line">kind: ServiceAccount</div><div class="line">metadata:</div><div class="line">  name: elasticsearch</div></pre></td></tr></table></figure></p>
<p>部署指令<br><code>kubectl create -f .</code><br>查看工作<br><code>kubectl get pods</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[centos@179 EFK]$ kubectl get pods</div><div class="line">NAME       READY     STATUS    RESTARTS   AGE</div><div class="line">es-3c69r   1/1       Running   0          1d</div></pre></td></tr></table></figure></p>
<p>查看日志<br><code>kubectl logs es-3c69r</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">[centos@179 EFK]$ kubectl logs es-3c69r</div><div class="line">[2017-12-01 22:50:17,664][INFO ][node                     ] [Legion] version[1.7.1], pid[1], build[b88f43f/2015-07-29T09:54:16Z]</div><div class="line">[2017-12-01 22:50:17,664][INFO ][node                     ] [Legion] initializing ...</div><div class="line">[2017-12-01 22:50:17,811][INFO ][plugins                  ] [Legion] loaded [], sites []</div><div class="line">[2017-12-01 22:50:17,877][INFO ][env                      ] [Legion] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [9.7gb], net total_space [9.9gb], types [rootfs]</div><div class="line">[2017-12-01 22:50:20,781][INFO ][node                     ] [Legion] initialized</div><div class="line">[2017-12-01 22:50:20,783][INFO ][node                     ] [Legion] starting ...</div><div class="line">[2017-12-01 22:50:21,052][INFO ][transport                ] [Legion] bound_address &#123;inet[/0:0:0:0:0:0:0:0:9300]&#125;, publish_address &#123;inet[/10.7.28.4:9300]&#125;</div><div class="line">[2017-12-01 22:50:21,088][INFO ][discovery                ] [Legion] elasticsearch/tfcW-qCYTa6Eq27G-ts6-Q</div><div class="line">[2017-12-01 22:50:24,172][INFO ][cluster.service          ] [Legion] detected_master [Lockdown][TepMZvL3T_O5Yu2YeMPn_A][es-qg67z][inet[/10.7.28.2:9300]], added &#123;[Lockdown][TepMZvL3T_O5Yu2YeMPn_A][es-qg67z][inet[/10.7.28.2:9300]],&#125;, reason: zen-disco-receive(from master [[Lockdown][TepMZvL3T_O5Yu2YeMPn_A][es-qg67z][inet[/10.7.28.2:9300]]])</div><div class="line">[2017-12-01 22:50:24,223][INFO ][http                     ] [Legion] bound_address &#123;inet[/0:0:0:0:0:0:0:0:9200]&#125;, publish_address &#123;inet[/10.7.28.4:9200]&#125;</div><div class="line">[2017-12-01 22:50:24,223][INFO ][node                     ] [Legion] started</div></pre></td></tr></table></figure></p>
<p>扩展节点Scale<br><code>kubectl scale --replicas=3 rc es</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[centos@179 EFK]$ kubectl get pods</div><div class="line">NAME       READY     STATUS    RESTARTS   AGE</div><div class="line">es-3c69r   1/1       Running   0          1d</div><div class="line">es-qg67z   1/1       Running   0          1d</div><div class="line">es-z11hm   1/1       Running   0          1d</div></pre></td></tr></table></figure></p>
<p>查看日志<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">[centos@179 EFK]$ kubectl logs es-qg67z</div><div class="line">[2017-12-01 22:49:45,616][INFO ][node                     ] [Lockdown] version[1.7.1], pid[1], build[b88f43f/2015-07-29T09:54:16Z]</div><div class="line">[2017-12-01 22:49:45,617][INFO ][node                     ] [Lockdown] initializing ...</div><div class="line">[2017-12-01 22:49:45,738][INFO ][plugins                  ] [Lockdown] loaded [], sites []</div><div class="line">[2017-12-01 22:49:45,799][INFO ][env                      ] [Lockdown] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [9.7gb], net total_space [9.9gb], types [rootfs]</div><div class="line">[2017-12-01 22:49:48,226][INFO ][node                     ] [Lockdown] initialized</div><div class="line">[2017-12-01 22:49:48,227][INFO ][node                     ] [Lockdown] starting ...</div><div class="line">[2017-12-01 22:49:48,397][INFO ][transport                ] [Lockdown] bound_address &#123;inet[/0:0:0:0:0:0:0:0:9300]&#125;, publish_address &#123;inet[/10.7.28.2:9300]&#125;</div><div class="line">[2017-12-01 22:49:48,441][INFO ][discovery                ] [Lockdown] elasticsearch/TepMZvL3T_O5Yu2YeMPn_A</div><div class="line">[2017-12-01 22:49:52,221][INFO ][cluster.service          ] [Lockdown] new_master [Lockdown][TepMZvL3T_O5Yu2YeMPn_A][es-qg67z][inet[/10.7.28.2:9300]], reason: zen-disco-join (elected_as_master)</div><div class="line">[2017-12-01 22:49:52,272][INFO ][http                     ] [Lockdown] bound_address &#123;inet[/0:0:0:0:0:0:0:0:9200]&#125;, publish_address &#123;inet[/10.7.28.2:9200]&#125;</div><div class="line">[2017-12-01 22:49:52,273][INFO ][node                     ] [Lockdown] started</div><div class="line">[2017-12-01 22:49:52,291][INFO ][gateway                  ] [Lockdown] recovered [0] indices into cluster_state</div><div class="line">[2017-12-01 22:50:24,144][INFO ][cluster.service          ] [Lockdown] added &#123;[Legion][tfcW-qCYTa6Eq27G-ts6-Q][es-3c69r][inet[/10.7.28.4:9300]],&#125;, reason: zen-disco-receive(join from node[[Legion][tfcW-qCYTa6Eq27G-ts6-Q][es-3c69r][inet[/10.7.28.4:9300]]])</div></pre></td></tr></table></figure></p>
<p>查看服务<br><code>kubectl get svc</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[centos@179 EFK]$ kubectl get svc</div><div class="line">NAME     CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE</div><div class="line">elasticsearch 10.254.156.16 &lt;pending&gt;  9200:31451/TCP,9300:31685/TCP   1d</div></pre></td></tr></table></figure></p>
<p>通过访问31451可以<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">[centos@179 EFK]$ curl node2:31451/_cluster/health?pretty</div><div class="line">&#123;</div><div class="line">  &quot;cluster_name&quot; : &quot;elasticsearch&quot;,</div><div class="line">  &quot;status&quot; : &quot;green&quot;,</div><div class="line">  &quot;timed_out&quot; : false,</div><div class="line">  &quot;number_of_nodes&quot; : 2,</div><div class="line">  &quot;number_of_data_nodes&quot; : 2,</div><div class="line">  &quot;active_primary_shards&quot; : 0,</div><div class="line">  &quot;active_shards&quot; : 0,</div><div class="line">  &quot;relocating_shards&quot; : 0,</div><div class="line">  &quot;initializing_shards&quot; : 0,</div><div class="line">  &quot;unassigned_shards&quot; : 0,</div><div class="line">  &quot;delayed_unassigned_shards&quot; : 0,</div><div class="line">  &quot;number_of_pending_tasks&quot; : 0,</div><div class="line">  &quot;number_of_in_flight_fetch&quot; : 0</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>

        </div>
      </article>
    </div>
    <!-- Pre or Next -->
    
	<div class="container" >
           <ul class="pager">
    	     
           
              <li class="next">
              <a href="/2017/08/17/05. coreos搭建.html" rel="prev">上一篇</a>
            </li>
           
          </ul>
       </div>
　　　　<!-- Comments -->
    <div class="container">
      
<section id="comment">
  <!-- <h1 class="title">Comments</h1> -->

  
</section>


    </div>
   
　　　　
  </div>
</div>


  <!-- Footer -->
  <!-- Footer -->
<footer class="site-info">
  <p>
    <span>thk_days &copy; 2017</span>
    
      <span class="split">|</span>
      <span>zxc</span>
    
  </p>
  <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  本站总访问量<span id="busuanzi_value_site_pv"></span>次
  本站访客数<span id="busuanzi_value_site_uv"></span>人次
</footer>


  <!-- After footer scripts -->
  <!-- scripts -->
<script src="/js/app.js"></script>



</body>

</html>
